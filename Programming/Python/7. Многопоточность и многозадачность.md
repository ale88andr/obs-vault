![[Pasted image 20230710094332.png]]

**Параллельность** - Это способность центрального процессора CPU или одного ядра в многоядерном процессоре **одновременно выполнять несколько процессов или потоков**, соответствующим образом поддерживаемых операционной системой. Параллельность хорошо применима при операциях с **CPU** (**CPU Bound**).

**Concurrency**, или **конкурентность** - все операции выполняются вместе, но не одновременно. Именно этот подход реализован в библиотеке **`asyncio`**.

![[Pasted image 20231214091531.png]]
### 7.0.1 Что такое `CPU` и `IO` bound операции?

**IO Bound** — операция, скорость выполнения которой ограничена скоростью подсистемы ввода-вывода. К таким задачам можно отнести выполнение запросов по сети, операции с базой, чтение/запись файла на диск.

![[Pasted image 20231214091904.png]]
Примеры **IO Bound** операций:

- `http`-запрос:

```Python
r = requests.get('https://api.github.com/user', auth=('user', 'pass'))
```

- `SQL`-запрос в базу:

```Python
users = conn.execute("SELECT * FROM users")
```

- Чтение файла:

```Python
data = open('text.txt').read()
```

**CPU Bound** — операция, скорость выполнения которой ограничена скоростью `CPU`, например, умножение матриц.

Пример **CPU Bound** операции:

- Простое увеличение счетчика на единицу и сравнение его значения с 500 000:

```Python
def countdown():
    i = 0
    while i < 500000:
        i += 1
```
## 7.1 Многопоточность

### 7.1.1 Многопоточность в Python и ее ограничения

**Поток** (**Thread**) - это базовая единица выполнения в операционной системе, состоящая из счетчика команд, стека и набора регистров. Процессы приложения могут быть построены с использованием нескольких потоков, которые могут работать одновременно и совместно использовать одну память.

При многопоточности все потоки процесса используют общий код и другие ресурсы
вроде данных и системных файлов. Для каждого потока вся связанная с ним информация хранится как структура данных внутри ядра операционной системы и
называется **Блок Управления Потоком** (`Thread Control Block`, `ТСВ`). `ТСВ` состоит
из нескольких основных компонентов:
- **Счетчик команд** (Program Counter, РС): отслеживает ход выполнения программы.
- **Системные регистры** (System Registers, REG): хранят переменные данные.
- **Стек** (Stack): массив регистров, который управляет историей выполнения.

> Многопоточность - это концепция операционной системы, которая предлагается системным ядром. ОС обеспечивает параллельное выполнение нескольких потоков в контексте одного процесса, позволяя потокам совместно использовать память. Это означает, что полный контроль над управлением потоков имеет ОС, а не приложение.

При выполнении потоков на компьютере с одним цен.тральным процессором (ЦП)
операционная система переключает его с одного потока на другой, поэтому кажется,
что потоки выполняются параллельно.

Несколько потоков в процессе:
![[Pasted image 20231213131200.png]]

С точки зрения программирования многопоточность - это подход, при котором
мы выполняем разные части приложения одновременно. Python использует множество потоков ядра для выполнения пользовательских потоков.

Реализация Python (**CPython**) позволяет потокам обращаться к объектам через глобальную блокировку интерпретатора (**Global Interpreter Lock**, `GIL`). В двух словах, `GIL` - это мьютекс (`mutex`, **механизм взаимного исключения**), который позволяет использовать интерпретатор только одному потоку за раз и блокирует остальные потоки. Это необходимо для защиты счетчика ссылок от сборки мусора. Без такой защиты счетчик может быть поврежден, если он обновляется несколькими потоками одновременно. Причиной такого ограничения является защита внутренних структур данных интерпретатора и стороннего кода `С`, который не является потокобезопасным.

> Это ограничение глобальной блокировки интерпретатора отсутствует в других реализациях Python - **Jython** и **lronPython**.

Создается впечатление, что написание многопоточных программ на Python не имеет
преимуществ, но это не так. Мы по-прежнему можем писать код, который будет
выполняться одновременно или параллельно, и мы можем увидеть это на примере.
Многопоточность полезна в следующих случаях:
- Задачи ввода-вывода: при наличии нескольких операций ввода-вывода можно повысить производительность, используя несколько потоков. Пока один поток ждет ответа от ресурса, он освобождает `GIL` и позволяет работать другим потокам. Исходный поток возобновится после ответа от ресурса ввода-вывода.
- Адаптивные GUI-приложения: в них требуется отображать ход выполнения задач, запущенных в фоновом режиме (например, загрузка файла), а также давать пользователю взаимодействовать с другими компонентами интерфейса. Это возможно благодаря отдельным потокам для действий, инициированных пользователем в графическом интерфейсе.
- Многопользовательские приложения: здесь также необходима многопоточность, например, для веб-сервера или файлового сервера. В таких приложениях при поступлении нового запроса в основном потоке создается новый поток, который будет обслуживать этот запрос, пока основной поток ожидает новых запросов.

### 7.1.2 Модуль `threading`

Модуль `threading` является стандартным и предоставляет простые методы для создания нескольких потоков программы. Внутри он использует низкоуровневый модуль `_thread`, который часто использовался для реализации многопоточности в более ранних версиях Python.

Для нового потока создадим объект класса `Thread`, который может принимать имя
функции в качестве атрибута `target` и аргументы в качестве атрибута `args` для передачи в функцию. Потоку можно при создании задать имя с помощью аргумента `name` в конструкторе. 

После создания объекта нужно запустить поток методом `start`. Реализовать, что основная программа или поток будут ждать завершения созданных потоковых объектов, можно с помощью метода `join`. Этот метод гарантирует, что главный поток (вызывающий поток) ожидает, пока поток, для которого вызван метод `join`, не завершит выполнение.

```Python
from threading import current_thread, Thread as Tread
from time import sleep


def print_hello():
    sleep(2)
    print(f'{current_thread().name}: Hello')


def print_message(msg):
    sleep(1)
    print(f'{current_thread().name}: {msg}')


# создаем потоки
t1 = Tread(target=print_hello, name='Tread #1')
t2 = Tread(target=print_hello, name='Tread #2')
t3 = Tread(target=print_message, args=['Good morning'], name='Tread #3')

# запускаем потоки
t1.start()
t2.start()
t3.start()

# ждем, пока все завершатся
t1.join()
t2.join()
t3.join()
```

Потоки 1 и 2 имеют большее время ожидания, чем поток 3, поэтому он всегда будет
завершаться первым. А потоки 1 и 2 могут завершаться в любом порядке, в зависимости от того кто первый получит процессор.

**Потоки-демоны**

В приложении главная программа неявным образом ждет завершения всех остальных потоков. Но иногда необходимо запустить некоторые из них в фоновом режиме, не блокируя основную программу. Такие потоки называаются потоками-демонами(Daemon Thread). Они остаются активными, пока выполняется главная
программа (с обычными потоками). Потоки-демоны часто используют в ситуациях, когда не будет ошибкой, если поток внезапно завершится посреди выполнения без потери или повреждения данных.

Поток может быть объявлен демоном, используя один из следующих подходов:
- Передать атрибут `daemon` со значением True конструктору (`daemon = true`).
- Задать для атрибута `daemon` значение True в экземпляре потока (`thread.daemon = True`).

Если поток установлен как демон, можно запустить его и забыть. Он завершится
автоматически после окончания программы, которая его вызвала.

**Синхронизация потоков**

**Синхронизация потоков** - это механизм, который не позволяет двум или более
потокам выполнять один блок кода одновременно. Блок кода, который обращается
к общим данным или ресурсам, называется критической секцией (Critical Section).

![[Pasted image 20231213140027.png]]

Когда несколько потоков, обращающихся к критической секции, одновременно пытаются получить доступ к данным или изменить их, результаты могут быть непредсказуемыми. Такая ситуация называется **состоянием гонки**(**Race condition**).

Обойти **состоянием гонки** можно с помощью синхронизации потоков, которая использует класс `Lock` из модуля `threading`. Замок (`Lock`) для блокировки потоков реализуется с помощью объекта **семафора**, предоставленного операционной системой. **Семафор** (Semaphore) - это объект синхронизации на уровне ОС для управления доступом к ресурсам и данным для нескольких процессоров и потоков. Класс `Lock` предоставляет два метода, `acquire` и `release`:
1. Метод `acquire` используется для получения замка, который имеет два состояния - заблокирован (по умолчанию) или разблокирован. Когда замок заблокирован, выполнение запрашивающего потока приостанавливается, пока замок не будет освобожден текущим потоком. Как только замок освобождается, он передается запрашивающему потоку. При запросе незаблокированного замка выполнение потока не блокируется. Если замок доступен (имеет состояние `unlocked`), запрашивающий поток получает его ( состояние становится `locked`). В противном случае запрашивающий поток получает `False` в качестве ответа на запрос замка.
2. Метод `release` используется для освобождения замка, то есть состояние принудительно переходит в `unlocked`. Если какой-то поток заблокирован и ждет получения замка, данный метод позволит начать выполнение.

```Python
from threading import Lock, Thread as Thread


# глобальная переменная
x = 0

def inc(lock):
    global x
    for _ in range(1000000):
	    # блокируем код
        lock.acquire()
        x += 1
        # освобождаем код
        lock.release()


lock = Lock()
# создаем потоки
tl = Thread(target=inc, args=[lock], name="Th 1")
t2 = Thread(target=inc, args=[lock], name="Th 2")

# запускаем потоки
tl. start ()
t2 .start()

# ожидаем завершения потоков
tl. join ()
t2. join ()

print("final value of х :", x)
```

## 7.2 Асинхронность (Многозадачность)

*Многопроцессорность* и *многопоточность* относятся к **синхронному программированию**, где отправляется запрос и ожидается ответ, прежде чем будет выполнен следующий блок кода. И если какое-либо переключение контекста и применяется, то это обеспечивается операционной системой. 

Асинхронное программирование в Python отличается двумя аспектами:
- Задачи должны быть созданы для асинхронного выполнения; это означает, что родительскому вызывающему объекту не нужно ждать ответа от другого процесса; тот ответит, как только закончит выполнение.
- **Операционная система больше не управляет переключением контекста между процессами и потоками**; асинхронная программа получит только один поток в процессе, но его возможности будут разнообразны; при таком стиле выполнения каждый процесс или задача добровольно передают контроль в случае простоя или ожидания другого ресурса.

**Виды многозадачности**:
- **Вытесняющая многозадачность** - В этой модели мы позволяем операционной системе решить, как переключаться между выполняемыми задачами с помощью процедуры квантования времени. Когда операционная система переключает за- дачи, мы говорим, что имеет место вытеснение. Как устроен этот механизм, зависит от операционной системы. Обычно для этого используется либо несколько потоков, либо несколько процессов.
- **Кооперативная многозадачность** - В этой модели мы не полагаемся для переключения между задачами на операционную систему, а явно определяем в коде приложения точки, где можно уступить управление другой задаче. Исполняемые задачи кооперируются, т. е. говорят приложению: «*Я сейчас на время приостановлюсь, а ты можешь пока выполнять другие задачи*».

В `asyncio` для организации конкурентности используется **кооперативная многозадачность**. Когда приложение доходит до точки, в которой может подождать результата, мы явно помечаем это в коде. Поэтому другой код может работать, пока мы ждем получения результата, вычисляемого в фоновом режиме. Как только вычисление результата завершится, мы «просыпаемся» и возобновляем задачу.

У **кооперативной многозадачности** есть ряд преимуществ перед вытесняющей. 
- кооперативная многозадачность потребляет меньше ресурсов. Когда операционной системе нужно переключиться между потоками или процессами, мы говорим, что имеет место контекстное переключение. Это трудоемкая операция, потому что операционная система должна сохранить всю информацию о работающем процессе или потоке, чтобы потом его можно было возобновить.
- Операционная система приостанавливает поток или процесс в соответствии со своим алгоритмом планирования, но выбранный для этого момент не всегда оптимален. В случае кооперативной многозадачности мы явно помечаем точки, в которых приостановить задачу наиболее выгодно. Это дает выигрыш в эффективности, потому что мы переключаем задачи именно в тот момент, когда это нужно.

**Кооперативная многозадачность** (Cooperative Multitasking) - это эффективный
инструмент для достижения параллелизма на уровне приложения. При таком подходе создаются не процессы или потоки, а **задачи**, которые включают *тасклеты* (Tasklet), *корутины* (Coroutine) и *зеленые потоки* (Green Thread). Они координируются одной функцией, которая называется **циклом событий** (**Event Loop**). Он регистрирует задачи и обрабатывает поток управления между ними. Прелесть
заключается в том, что цикл событий в Python реализуется **с помощью генераторов**.
А, значит, они могут выполнять функцию и приостанавливать ее в определенной
точке (с помощью `yield`), сохраняя при этом контроль над стеком объектов до возобновления работы.

Для систем, основанных на кооперативной многозадачности, всегда стоит вопрос,
когда возвращать управление планировщику или циклу событий. Наиболее популярная логика заключается в использовании операций ввода-вывода в качестве событий для освобождения управления, поскольку для этих операций всегда требуется время ожидания.

>В случае *многопоточности* ОС управляет переключением контекста между потоками и может вытеснить любой запущенный поток по любой причине и передать управление другому. Но **при асинхронном программировании или кооперативной многозадачности операционной системе не видны задачи и корутины**. Фактически они не могут быть вытеснены главным циклом событий.

Современные версии Python поддерживают разработку так называемого **"асинхронного кода"** посредством написания **"сопрограмм"** с использованием синтаксиса **`async` и `await`**.

### 7.2.0 Что такое ограниченность производительностью ввода-вывода(IO Bound) и ограниченность быстродействием процессора(CPU Bound)

Операция, ограниченная быстродействием процессора (счетная операция), зависит от мощности процессора(например с частотой 3, а не 2 ГГц).

Операция, ограниченная производительностью ввода-вывода, зависит от того, сколько устройство способно обработать(получить) данных за единицу времени(для этого можно было бы увеличить пропускную способность сети или поставив более шуструю сетевую карту).

Счетные операции в Python – это обычно вычисления и обработка данных. Примерами могут служить вычисления цифр числа `π` или применение бизнес-логики к каждому элементу словаря. 

В случае операции, ограниченной вводом-выводом, мы тратим большую часть
времени на ожидание ответа от сети или другого устройства. 
Примерами могут служить запрос к веб-серверу или чтение файла с жесткого диска.

![[Pasted image 20231218131228.png]]

> Асинхронный ввод-вывод позволяет *приостановить* выполнение метода, встретив операцию ввода-вывода; ожидая завершения этой операции, работающей в фоновом режиме, мы можем выполнять другой код. Это позволяет выполнять одновременно много операций ввода-вывода и тем самым ускорить работу приложения.
### 7.2.1 Асинхронный код

Асинхронный код означает, что в языке есть возможность сообщить машине / программе, что в определённой точке кода ей нужно будет ожидать завершения выполнения _чего-то ещё_ в другом месте. Допустим это _что-то ещё_ называется "медленный файл".

И пока мы ждём завершения работы с "медленным файлом", компьютер может переключиться для выполнения других задач.

Но при каждой возможности компьютер / программа будет возвращаться обратно. Например, если он опять окажется в режиме ожидания, или когда закончит всю работу. В этом случае компьютер проверяет, не завершена ли какая-нибудь из текущих задач.

Потом он берёт первую выполненную задачу (допустим, наш "медленный файл") и продолжает работу, производя с ней необходимые действия.

Вышеупомянутое "что-то ещё", завершения которого приходится ожидать, обычно относится к достаточно "медленным" операциям I/O (по сравнению со скоростью работы процессора и оперативной памяти), например:
- отправка данных от клиента по сети
- получение клиентом данных, отправленных вашей программой по сети
- чтение системой содержимого файла с диска и передача этих данных программе
- запись на диск данных, которые программа передала системе
- обращение к удалённому API
- ожидание завершения операции с базой данных
- получение результатов запроса к базе данных
- и т. д.

Поскольку в основном время тратится на ожидание выполнения операций I/O, их обычно называют операциями, ограниченными скоростью ввода-вывода.

Код называют "асинхронным", потому что компьютеру / программе не требуется "синхронизироваться" с медленной задачей и, будучи в простое, ожидать момента её завершения, с тем чтобы забрать результат и продолжить работу.

Вместо этого в "асинхронной" системе завершённая задача может немного подождать (буквально несколько микросекунд), пока компьютер / программа занимается другими важными вещами, с тем чтобы потом вернуться, забрать результаты выполнения и начать их обрабатывать.

"Синхронное" исполнение (в противовес "асинхронному") также называют "последовательным", потому что компьютер / программа последовательно выполняет все требуемые шаги перед тем, как перейти к следующей задаче, даже если в процессе приходится ждать.

> **Различие между конкурентностью и параллелизмом**
> Конкурентность возможна, когда несколько задач может работать независимо друг от друга. Конкурентность можно организовать, имея процессор всего с одним ядром, применив вытесняющую многозадачность для переключения между задачами. С другой стороны, параллелизм означает, что мы должны выполнять две задачи или более строго одновременно.

---
### 7.2.2 `async` и `await

В современных версиях Python разработка асинхронного кода реализована очень интуитивно. Он выглядит как обычный "последовательный" код и самостоятельно выполняет "ожидание", когда это необходимо.

Если некая операция требует ожидания перед тем, как вернуть результат, код можно написать следующим образом:

```Python
burgers = await get_burgers(2)
```

Главное здесь слово `await`. Оно сообщает интерпретатору, что необходимо дождаться пока `get_burgers(2)` закончит свои дела, и только после этого сохранить результат в `burgers`. Зная это, Python может пока переключиться на выполнение других задач (например получение следующего запроса).

Чтобы ключевое слово `await` сработало, оно должно находиться внутри функции, которая поддерживает асинхронность. Для этого вам просто нужно объявить её как `async def`:

```Python
# Готовим бургеры по специальному асинхронному рецепту
async def get_burgers(number: int):     
	return burgers
```

...вместо `def`:

```Python
# Это не асинхронный код
# Готовим бургеры последовательно по шагам
def get_sequential_burgers(number: int):    
	return burgers
```

Объявление `async def` указывает интерпретатору, что внутри этой функции следует ожидать выражений `await`, и что можно поставить выполнение такой функции на "паузу" и переключиться на другие задачи, с тем чтобы вернуться сюда позже.

Если вы хотите вызвать функцию с `async def`, вам нужно "ожидать" её. Поэтому такое не сработает:

```Python
# Это не заработает, поскольку get_burgers объявлена с использованием async def 
burgers = get_burgers(2)
```

Если сторонняя библиотека требует вызывать её с ключевым словом `await`, необходимо писать _функции обработки пути_ с использованием `async def`

---

### 7.2.3 Сопрограммы

**Корути́на** (или же сопрограмма) — это понятие для именования той сущности, которую возвращает функция `async def`. Python знает, что её можно запустить, как и обычную функцию, но кроме того сопрограмму можно поставить на паузу в том месте, где встретится слово `await`.

Всю функциональность асинхронного программирования с использованием `async` и `await` часто обобщают словом "корутины". Они аналогичны "горутинам", ключевой особенности языка Go.

### 7.2.4 Как работает цикл событий

**Цикл событий** – сердце любого приложения `asyncio`. Этот паттерн проектирования встречается во многих системах и был придуман уже довольно давно.

По сути своей цикл событий очень прост. Мы создаем очередь, в которой хранится список событий или сообщений, а затем входим в бесконечный цикл, где обрабатываем сообщения по мере их поступления.

```Python
from collections import deque

messages = deque()

while True:
	if messages:
		message = messages.pop()
		process_message(message)
```

В `asyncio` цикл событий управляет очередью задач. Задача – это обертка вокруг сопрограммы. Сопрограмма может приостановить выполнение, встретив операцию ввода-вывода, и дать циклу событий возможность выполнить другие задачи, которые не ждут завершения ввода-вывода.

Создавая цикл событий, мы создаем **пустую очередь задач**. Затем добавляем в эту очередь задачи для выполнения. На каждой итерации цикла проверяется, есть ли в очереди готовая задача, и если да, то она выполняется, пока не встретит операцию ввода-вывода. В этот момент задача приостанавливается, и мы просим операционную систему наблюдать за ней. А сами тем временем переходим к следующей готовой задаче. На каждой итерации проверяется, завершилась ли какая-нибудь операция ввода-вывода; если да, то ожидавшие ее завершения задачи пробуждаются и им предоставляется возможность продолжить работу.

![[Pasted image 20231218135613.png]]
### 7.2.4 Модуль `asyncio`

Модуль `asyncio` доступен, начиная с Python `3.5` и более поздних версиях. Он предназначен для написания конкурентных программ с помощью синтаксиса `async/await`. Но для сложных приложений рекомендуется использовать Python, начиная с версии `3.7`. Библиотека богата множеством возможностей, поддерживает создание и выполнение корутинов, выполнение сетевых операций ввода-вывода, распределение задач по очередям и синхронизацию параллельного кода.

#### 7.2.4.1  Сопрограммамы(корутины)

**Сопрограмму** можно рассматривать как обычную функцию Python, наделенную способностью приостанавливаться, встретив операцию, для выполнения которой нужно заметное время. По завершении такой длительной операции сопрограмму можно возобновить, после чего она продолжит выполнение.

Для создания и приостановки сопрограммы в Python используются ключевые слова `async` и `await`:
- `async` определяет сопрограмму;
- `await` приостанавливает ее на время выполнения длительной операции.

Создать сопрограмму так же просто, как обычную функцию Python, только вместо ключевого слова `def` нужно использовать `async def`. Ключевое слово `async` говорит, что это сопрограмма, а не обычная функция.

```Python
async def my_coroutine() -> None:
    print('Hello world!')

result = my_coroutine()

print(f'Результат сопрограммы равен {result}, а его тип равен {type(result)}')
```

```Shell
Результат сопрограммы равен <coroutine object my_coroutine at 0x00000000024834C0>, а его тип равен <class 'coroutine'>
```

> Отметим, что функция выше **не выполняет никаких длительных операций**, просто печатает и возвращает управление. Это значит, что после передачи циклу событий эта сопрограмма будет выполнена **немедленно, поскольку никакого блокирующего ввода-вывода нет и ничто не вынуждает ее приостановитьс**я.

В результате выполнения данной функции, код сопрограммы `my_coroutine` вообще не выполняется, а вернется объект сопрограммы.

Это важный момент – сопрограммы **не выполняются, если их вызвать напрямую**. Вместо этого возвращается объект сопрограммы, который будет выполнен позже. **Чтобы выполнить сопрограмму, мы должны явно передать ее циклу событий**.

Наиболее простой способ передать сопрограмму в цикл событий, тем самым выполнить её - это вспомогательная функция `asyncio.run` 

```Python
import asyncio

async def my_coroutine() -> None:
    print('Hello world!')

result = asyncio.run(my_coroutine())
```

В этом случае `asyncio.run` делает несколько важных вещей. Во-первых, она создает новое событие. Потом она выполняет код переданной нами сопрограммы до конца и возвращает результат. Эта функция также подчищает все то, что могло остаться после завершения сопрограммы. И в конце она останавливает и закрывает цикл событий.

#### 7.2.4.2  Приостановка выполнения с помощью ключевого слова `await`

Истинное достоинство `asyncio` – возможность приостановить выполнение и дать циклу событий возможность выполнить другие задачи, пока длительная операция делает свое дело. Для приостановки выполнения служит ключевое слово `await`, за ним обычно следует обращение к сопрограмме (точнее, к объекту, допускающему ожидание, который необязательно является сопрограммой).

Использование ключевого слова `await` приводит к выполнению следующей за ним сопрограммы, а не просто к возврату объекту сопрограммы, как при прямом вызове.

Ключевое слово `await` следует поместить перед вызовом сопрограммы.

```Python
import asyncio

async def add_one(number: int) -> int:
    return number + 1

async def main():
	# Приостановиться и ожидать результата add_one(1)
    one_plus_one = await add_one(1)
    # Приостановиться и ожидать результата add_one(2)
    two_plus_one = await add_one(2)
    print(one_plus_one, two_plus_one, sep='\n')

asyncio.run(main())
```

В листинге мы приостанавливаем выполнение дважды. Сначала ждем завершения `add_one(1)`. После получения результата выполнение функции `main` возобновляется, и мы присваиваем значение, возвращенное `add_one(1)`, переменной `one_plus_one`, в данном случае она станет равна `2`. Затем то же самое мы проделываем с `add_one(2)`, после чего печатаем результаты. Поток выполнения изображен на рис. в блоках показано, что происходит в одной или нескольких строках кода.
![[Pasted image 20231218144230.png]]
> Встретив выражение `await`, интерпретатор приостанавливает родительскую сопрограмму и выполняет сопрограмму в выражении `await`. По ее завершении родительская сопрограмма возобновляется и возвращенное ей значение присваивается переменной.

**Моделирование длительных операций с помощью `sleep`**

Функция `asyncio.sleep` заставляет сопрограмму «заснуть» на заданное число секунд, т. е. приостанавливает ее на заданное время. Это позволяет смоделировать, что происходит при обращении к базе данных или веб-ресурсу.

```Python
import asyncio


async def hw_message() -> str:
    # Приостановить hello_world_message на 1 с
    await asyncio.sleep(1)
    return 'Hello world!'


async def main() -> None:
    # Приостановить main до завершения hw_message()
    message = await hw_message()
    print(message)

asyncio.run(main())
```

Эта программа ждет 1 с, а затем печатает сообщение `«Hello World!»`.
Поскольку `hw_message` – сопрограмма, а мы приостановили ее на 1 с, у нас появилась одна секунда, в течение которой мог бы конкурентно работать другой код.

#### 7.2.4.3 Конкурентное выполнение с помощью задач

> Располагая только инструментами `async`, `await` и `asyncio.run`, мы можем написать асинхронный код, но не можем выполнить его конкурентно. А чтобы это сделать, нужны задачи.

**Задача** – это обертка вокруг сопрограммы, которая планирует выполнение последней в цикле событий как можно раньше. И планирование, и выполнение происходят в неблокирующем режиме, т. е., создав задачу, мы можем сразу приступить к выполнению другого кода, пока эта задача работает в фоне. Сравните с ключевым словом `await`, которое блокирует выполнение, т. е. мы приостанавливаем
всю сопрограмму на время, пока выражение `await` не вернет управление.

Для создания задачи служит функция `asyncio.create_task`. Ей передается подлежащая выполнению сопрограмма, а в ответ она немедленно возвращает объект задачи. Этот объект можно включить в выражение `await`, которое извлечет возвращенное значение по завершении задачи.

```Python
import asyncio

async def delay(delay_seconds: int) -> int:
    print(f'засыпаю на {delay_seconds} с')
    await asyncio.sleep(delay_seconds)
    print(f'сон в течение {delay_seconds} с закончился')
    return delay_seconds

async def main():
    sleep_for_three = asyncio.create_task(delay(3))
    print(type(sleep_for_three))
    result = await sleep_for_three
    print(result)

asyncio.run(main())
```

Вывод

```Shell
<class '_asyncio.Task'>
засыпаю на 3 с
сон в течение 3 с закончился
3
```

Здесь мы создали задачу, которой для выполнения нужно 3 с. Кроме того, мы печатаем тип задачи, в данном случае `<class '_asyncio.Task'>`, чтобы показать, что это не сопрограмма. Следует также отметить, что `print` выполняется
сразу после запуска задачи. Если бы мы просто использовали `await` для сопрограммы `delay`, то увидели бы сообщение только через 3 с.

Пример конкурентного выполнения задач:

```Python
import asyncio

from util import delay


async def main():
    task_1 = asyncio.create_task(delay(3))
    task_2 = asyncio.create_task(delay(3))
    task_3 = asyncio.create_task(delay(3))

    await task_1
    await task_2
    await task_3

asyncio.run(main())
```

Вывод программы:

```Shell
засыпаю на 3 с
засыпаю на 3 с
засыпаю на 3 с
сон в течение 3 с закончился
сон в течение 3 с закончился
сон в течение 3 с закончился
```

**Поток выполнения программы в листинге**
![[Pasted image 20231218154417.png]]

Здесь мы запустили три задачи, каждой из которых для завершения нужно 3 с. Каждое обращение к `create_task` возвращает управление немедленно, поэтому до предложения `await task_1` мы доходим сразу же. Ранее мы отмечали, что выполнение задач планируется «как можно раньше». На практике это означает, что в точке, где встречается первое после создания задачи предложение `await`, все
ожидающие задачи начинают выполняться, так как `await` запускает очередную итерацию цикла событий.

#### 7.2.4.4 Снятие задач и задание тайм-аутов

Сетевые подключения ненадежны. Установленное пользователем подключение может быть разорвано из-за медленной сети, или веб-сервер может «упасть» и оставить существующие запросы в подвешенном состоянии. Поэтому, отправляя запросы, мы должны внимательно следить за ними, чтобы не ждать слишком долго. Иначе приложение может зависнуть, ожидая результата, который никогда не придет.

**Снятие задач**

Снять задачу просто. У каждого объекта задачи есть метод `cancel`, который можно вызвать, если требуется остановить задачу. В результате снятия задача возбудит исключение `CancelledError`, когда мы ждем ее с помощью `await`. Это исключения можно обработать, как того требует ситуация.

```Python
import asyncio
from asyncio import CancelledError
from util import delay

async def main():
	long_task = asyncio.create_task(delay(10))
	seconds_elapsed = 0
	while not long_task.done():
		print('Задача не закончилась, следующая проверка через секунду.')
		await asyncio.sleep(1)
		seconds_elapsed = seconds_elapsed + 1
		if seconds_elapsed == 5:
		long_task.cancel()
	
	try:
		await long_task
	except CancelledError:
		print('Наша задача была снята')

asyncio.run(main())
```

**Задание тайм-аута и снятие с помощью `wait_for`**

Проверять состояние каждую секунду или с другим интервалом, как в предыдущем примере, – не самый простой способ реализации таймаута. В идеале хотелось бы иметь вспомогательную функцию, которая позволяла бы задать тайм-аут и снять задачу по его истечении. В `asyncio` есть такая возможность в виде функции `asyncio.wait_for`. Она принимает объект сопрограммы или задачи и тайм-аут в секундах и возвращает сопрограмму, к которой можно применить `await`. Если задача не завершилась в отведенное время, то возбуждается исключение `TimeoutError` и задача автоматически снимается.

```Python
import asyncio
from util import delay

async def main():
    delay_task = asyncio.create_task(delay(2))
    try:
        result = await asyncio.wait_for(delay_task, timeout=1)
        print(result)
    except asyncio.exceptions.TimeoutError:
        print('Тайм-аут!')
        print(f'Задача была снята? {delay_task.cancelled()}')

asyncio.run(main())
```

Автоматическое снятие задачи, работающей дольше, чем ожидается, обычно является разумной практикой. В противном случае сопрограмма могла бы ждать неопределенно долго, занимая ресурсы, которые никогда не будут освобождены. Но в некоторых случаях желательно дать сопрограмме поработать. Например, по прошествии некоторого времени мы можем проинформировать пользователя
о том, что работа занимает дольше, чем ожидалось, но не снимать ее, когда тайм-аут истечет.

```Python
import asyncio
from util import delay


async def main():
    task = asyncio.create_task(delay(10))
    try:
        result = await asyncio.wait_for(asyncio.shield(task), 5)
        print(result)
    except asyncio.exceptions.TimeoutError:
        print("Задача заняла более 5 с, скоро она закончится!")
        result = await task
        print(result)

asyncio.run(main())
```

#### 7.2.4.5 Задачи, сопрограммы, будущие объекты и объекты, допускающие ожидание

**Введение в будущие объекты**

Объект `future` в Python содержит одно значение, которое мы ожидаем получить в будущем, но пока еще, возможно, не получили. В момент создания `future` не обертывает никакого значения, потому что его еще не существует. Объект в таком состоянии называется неполным, неразрешенным или просто неготовым. И только получив результат, мы можем установить значение объекта `future`, в результате чего он становится полным и из него можно извлечь результат.

```Python
from asyncio import Future
import asyncio


def make_request() -> Future:
    future = Future()
    asyncio.create_task(set_future_value(future))
    return future


async def set_future_value(future) -> None:
    await asyncio.sleep(1)
    future.set_result(42)


async def main():
    future = make_request()
    print(f'Будущий объект готов? {future.done()}')
    value = await future
    print(f'Будущий объект готов? {future.done()}')
    print(value)

asyncio.run(main())
```

Будущие объекты также можно использовать в выражениях `await`. Это означает «*я посплю, пока в будущем объекте не будет установлено значение, с которым я могу работать, а когда оно появится, разбуди меня и дай возможность его обработать*».

Между задачами и будущими объектами существует тесная связь. На самом деле `task` напрямую наследует `future`. Можно считать, что объект `future` представляет значение, которое появится только в будущем. А `task` является комбинацией сопрограммы и `future`. Создавая задачу, мы создаем пустой объект `future` и запускаем сопрограмму. А когда сопрограмма завершится с результатом или вследствие исключения, мы записываем этот результат или объект-исключение во
`future`.

Аналогичная связь и между задачами и сопрограммами, все эти типы можно использовать в выражениях `await`. Связующим звеном между ними является абстрактный базовый класс `Awaitable`. В нем определен единственный абстрактный метод `__await__`. т.е. любой объект, который реализует метод `__await__`, можно использовать в выражении `await`. Сопрограммы, как и будущие объекты, наследуют
`Awaitable` напрямую.
![[Pasted image 20231218170400.png]]

Далее будем называть объекты, которые можно использовать в выражениях `await`, объектами, допускающими ожидание (`awaitable`). Этот термин часто встречается в документации по `asyncio`, поскольку многие методы `API` готовы принимать и сопрограммы, и задачи, и будущие объекты.

#### 7.2.4.6 Распространенные ошибки сопрограмм и задач

Есть две основные ошибки на пути преобразования приложения в асинхронное. Первая – попытка выполнить счетный код в задачах или сопрограммах, не прибегая к многопроцессности, вторая – использовать блокирующие API ввода-вывода, пренебрегая многопоточностью.

**Выполнение счетного кода**

В программе могут быть функции, выполняющие длительные вычисления, например обход большого словаря или математические расчеты. Если есть возможность выполнять эти функции конкурентно, то может возникнуть идея поместить их в отдельные задачи. В принципе, ничего плохого в этом нет, но нужно помнить, что модель конкурентности в asyncio однопоточная. Это значит, что
действуют все ограничения одного потока и глобальной блокировки интерпретатора.
Однако при таком подходе мы можем оказаться в ситуации, когда производительность приложения падает. Особенно если в программе есть другие сопрограммы или задачи, в которых встречаются выражения `await`.

**Выполнение блокирующих API**

Может возникнуть соблазн использовать существующие библиотеки ввода-вывода, обернув их сопрограммами. Однако при этом возникнут те же проблемы, что для счетных операций. Эти API будут блокировать главный поток. Поэтому, попытавшись выполнить блокирующий вызов API в сопрограмме, мы заблокируем сам поток цикла событий, а значит, воспрепятствуем выполнению всех остальных сопрограмм
и задач. Примерами блокирующих API является библиотека `requests` или функция `time.sleep`. Вообще, любая функция, которая выполняет ввод-вывод, не являясь сопрограммой, или занимает процессор длительными операциями, может считаться **блокирующей**(т. е. блокирует поток, в котором выполняется). Поскольку `asyncio` **однопоточная**, библиотека `requests` или другая блокирующая функция блокирует цикл событий и не дает ничему выполняться конкурентно.

Большинство API, с которыми мы обычно работаем, в настоящее время являются блокирующими и без доработок работать с `asyncio` не будут. Нужно использовать библиотеку, которая поддерживает сопрограммы и неблокирующие сокеты. А это значит, что если используемая вами библиотека не возвращает сопрограммы и вы не употребляете `await` в собственных сопрограммах, то, вероятно, совершаете
блокирующий вызов.

### 7.2.5 Отладочный режим

При работе в отладочном режиме печатаются полезные сообщения, когда сопрограмма или задача работают больше 100 мс. Кроме того, если для некоторой сопрограммы отсутствует await, то возбуждается исключение, показывающее, в каком месте следовало бы добавить `await`. Есть несколько способов войти в отладочный режим:
- Использование `asyncio.run`

```Python
asyncio.run(coroutine(), debug=True)
```

- Использование аргументов командной строки

```Shell
python3 -X dev program.py
```

- Использование переменных окружения

```Shell
PYTHONASYINCIODEBUG=1 python3 program.py
```

### 7.2.6 Конкурентное выполнение запросов с помощью `gather`

Для конкурентного выполнения допускающих ожидание объектов широко используется функция `asyncio.gather`. Она принимает последовательность допускающих ожидание объектов и запускает их конкурентно всего в одной строке кода. Если среди объектов есть сопрограмма, то `gather` автоматически обертывает ее задачей, чтобы гарантировать конкурентное выполнение. Это значит, что не нужно отдельно обертывать все сопрограммы по отдельности с помощью
функции `asyncio.create_task`, как мы делали раньше.

`asyncio.gather` возвращает объект, допускающий ожидание. Если использовать его в выражении `await`, то выполнение будет приостановлено, пока не завершатся все переданные объекты. А когда это произойдет, `asyncio.gather` вернет список результатов работы.

Мы можем воспользоваться этой функцией, чтобы конкурентно отправить любое число веб-запросов. Рассмотрим пример, где имеется 1000 запросов и мы хотим получить все коды состояния.

```Python
import asyncio
import aiohttp

from utils import fetch_status

async def main():
    async with aiohttp.ClientSession() as session:
        urls = ['https://mail.ru' for _ in range(10)]
        requests = [fetch_status(session, url) for url in urls]
        status_codes = await asyncio.gather(*requests)
        print(status_codes)

asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())
asyncio.run(main())
```

Здесь мы сначала генерируем список URL-адресов, для которых хотим получить код состояния; для простоты все адреса равны. Затем берем этот список и вызываем `fetch_status`, чтобы получить список сопрограмм, который передадим `gather`.
При этом все сопрограммы обертываются задачами и запускаются конкурентно.

Стоит отметить, что порядок поступления результатов для переданных объектов, допускающих ожидание, не детерминирован. Например, если передать `gather` сопрограммы `a` и `b` именно в таком порядке, то `b` может завершиться раньше, чем `a`. Но приятная особенность `gather` заключается в том, что, независимо от порядка завершения допускающих ожидание объектов, результаты гарантированно будут возвращены в том порядке, в каком объекты передавались.

**Обработка исключений при использовании `gather`**

Ответ на веб-запрос приходит не всегда, иногда возникает исключение. Поскольку сети ненадежны, возможны различные сценарии отказов. Например, переданный адрес может не существовать или оказаться временно недоступным из-за остановки сайта. Сервер, к которому мы пытаемся подключиться, тоже может быть остановлен
или отказать в подключении.

`asyncio.gather` принимает необязательный параметр, `return_exceptions`,
который позволяет указать, как мы хотим обрабатывать исключения от допускающих ожидание объектов. Это булево значение, поэтому возможно два варианта:
- `return_exceptions=False` – это режим по умолчанию. Если хотя бы одна сопрограмма возбуждает исключение, то `gather` возбуждает то же исключение в точке `await`. Но, даже если какая-то сопрограмма откажет, остальные не снимаются и продолжат работать при условии, что мы обработаем исключение и оно не приведет к остановке цикла событий и снятию задач;
- `return_exceptions=True` – в этом случае исключения возвращаются в том же списке, что результаты. Сам по себе вызов `gather` не возбуждает исключений, и мы можем обработать исключения, как нам удобно.

```Python
import aiohttp
import asyncio

from utils import fetch_status

async def main():
    async with aiohttp.ClientSession() as session:
        urls = ['https://example.com', 'python://example.com']
        tasks = [fetch_status(session, url) for url in urls]
        results = await asyncio.gather(*tasks, return_exceptions=True)

        exceptions = [res for res in results if isinstance(res, Exception)]
        successful_results = [res for res in results if not isinstance(res, Exception)]

        print(f'Все результаты: {results}')
        print(f'Завершились успешно: {successful_results}')
        print(f'Завершились с исключением: {exceptions}')


asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())
asyncio.run(main())
```

Функция `gather` имеет несколько недостатков. Первый мы уже упоминали – не так просто отменить задачи, если одна из них возбудила исключение. Второй недостаток – необходимость дождаться завершения всех сопрограмм, прежде чем можно будет приступить к обработке результатов.

`Аsyncio` предлагает `API`, позволяющие решить обе проблемы.

**Обработка результатов по мере поступления**

`asyncio` предлагает функцию `as_completed`. Она принимает список допускающих ожидание объектов и возвращает итератор по будущим объектам. Эти объекты можно перебирать, применяя к каждому `await`. Когда выражение `await` вернет управление, мы получим результат первой завершившейся сопрограммы. Это значит, что мы сможем обрабатывать результаты по мере их доступности, но теперь порядок результатов не детерминирован, поскольку неизвестно, какой объект завершится первым.

```Python
import asyncio
import aiohttp

from utils import fetch_status


async def main():
    async with aiohttp.ClientSession() as session:
        fetchers = [fetch_status(session, 'https://www.example.com'),
                    fetch_status(session, 'https://www.example.com'),
                    fetch_status(session, 'https://www.example.com')]

        for finished_task in asyncio.as_completed(fetchers, timeout=2):
	        try:
		        result = await finished_task
		        print(result)
		    except asyncio.TimeoutError:
			    print('Произошел тайм-аут!')


asyncio.run(main())
```

Здесь мы создаем три сопрограммы – две из них завершаются примерно через 1 с, а третья через 10 с. Эти сопрограммы передаются функции `as_completed`. Под капотом каждая сопрограмма обертывается задачей и начинает выполняться конкурентно. Функция немедленно возвращает итератор, который мы начинаем обходить. Войдя в цикл `for`, мы сразу натыкаемся на `await finished_task`. Здесь выполнение приостанавливается до момента поступления первого результата. В данном случае первый результат поступит через 1 с, и мы напечатаем код состояния. Затем снова дойдем до `await finished_task`, и, так как запросы выполняются конкурентно, второй результат станет доступен почти мгновенно. Наконец, через 10 с завершится третий запрос, а вместе с ним и цикл.

Полное время обхода `result_iterator` по-прежнему составляет 10 с, как было бы при использовании `asynio.gather`, однако теперь результат первого запроса печатается сразу после получения. Это дает нам дополнительное время для обработки результата первой успешно завершившейся сопрограммы, пока остальные еще выполняются, поэтому приложение оказывается более отзывчивым.

`as_completed` справляется со своей задачей – возвращать результат по мере поступления, но она не лишена недостатков. Первый заключается в том, что хотя мы и получаем результаты в темпе их поступления, но невозможно сказать, какую сопрограмму или задачу мы ждем, поскольку порядок абсолютно не детерминирован. Если порядок нас не волнует, то и ладно, но если требуется ассоциировать результаты с запросами, то возникает проблема. Второй недостаток в том, что, хотя исключения по истечении тайм-аута возбуждаются как положено, все созданные задачи продолжают работать в фоновом режиме. А если мы захотим их снять, то будет трудно понять, какие задачи еще работают. Вот вам и еще одна проблема! Если эти проблемы требуется решить, то нужно точно знать, какие допускающие ожидание объекты уже завершились, а какие еще нет. Поэтому `asyncio` предоставляет функцию `wait`.

Функция `wait` в `asyncio` похожа на `gather`, но дает более точный контроль над ситуацией. У нее есть несколько параметров, позволяющих решить, когда мы хотим получить результаты. Кроме того, она возвращает два множества: задачи, завершившиеся успешно или в результате исключения, а также задачи, которые продолжают выполняться. Еще эта функция позволяет задать тайм-аут, который, однако, ведет себя не так, как в других функциях API: он не возбуждает исключений.

```Python
import asyncio
import aiohttp
import logging

from utils import fetch_status


async def main():
    async with aiohttp.ClientSession() as session:
        req_1 = fetch_status(session, 'https://example.com')
        req_2 = fetch_status(session, 'bad://example.com')

        fetchers = [asyncio.create_task(req_1), asyncio.create_task(req_2)]

        done, pending = await asyncio.wait(fetchers)

        print(f'Число завершившихся задач: {len(done)}')
        print(f'Число ожидающих задач: {len(pending)}')

        for done_task in done:
            if done_task.exception() is None:
                print(done_task.result())
            else:
                logging.error('При выполнении запроса возникло исключение', exc_info=done_task.exception())


asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())
asyncio.run(main())
```

**Обработка всех результатов по мере поступления**

```Python
import asyncio
import aiohttp
import logging

from utils import fetch_status


async def main():
    async with aiohttp.ClientSession() as session:
        url = 'https://mail.ru'

        pending = [
                asyncio.create_task(fetch_status(session, url)),
                asyncio.create_task(fetch_status(session, url)),
                asyncio.create_task(fetch_status(session, url))
            ]

        while pending:
            done, pending = await asyncio.wait(pending, return_when=asyncio.FIRST_COMPLETED)

            print(f'Число завершившихся задач: {len(done)}')
            print(f'Число ожидающих задач: {len(pending)}')

            for done_task in done:
                if done_task.exception() is None:
                    print(done_task.result())
                else:
                    logging.error('При выполнении запроса возникло исключение', exc_info=done_task.exception())


asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())
asyncio.run(main())
```

> Итого:
> - Функция `asyncio.gather` позволяет конкурентно запустить несколько сопрограмм и ждать их завершения. Она возвращает управление, когда завершатся все переданные ей объекты, допускающие ожидание. Если нужно отслеживать возникающие ошибки, то можно задать параметр `return_exeptions` равным `True`. Тогда будут возвращаться как результаты успешно завершившихся объектов, так и возникшие исключения.
> - Функция `as_completed` позволяет обрабатывать результаты списка допускающих ожидание объектов по мере их завершения. Она возвращает итератор по будущим объектам, который можно обойти. Как только сопрограмма или задача завершается, итератор отдает ее результат.
> - Если мы хотим выполнить несколько задач конкурентно, но при этом понимать, какие задачи уже завершились, а какие еще работают, то можем использовать функцию `wait`. Она также дает более точный контроль над моментом возврата результатов. После возврата мы получаем множество завершившихся задач и множество еще работающих. Затем можем отменить какие-то задачи или снова ждать их завершения.









## 7.3 Многопроцессорность

### 7.3.1 Многопроцессорная обработка

Для задач CPU-bound лучше выбрать иной подход - многопроцессорную обработку, поскольку глобальная блокировка интерпретатора `GIL` не ограничивает отдельные процессы и выполнение может происходить параллельно. Это особенно эффективно, когда приложения выполняются на многоядерных процессорах и интенсивно их используют. Во встроенных библиотеках Python многопроцессорная обработка - единственный вариант использования многоядерных процессоров.

> Графические процессоры (Graphics Processing Units, GPU) имеют большее количество ядер, чем обычные процессоры, и лучше подходят для задач параллельной обработки. Единственная сложность заключается в необходимости переноса данных из основной памяти в память графического процессора. Эти дополнительные действия окупятся при обработке большого объема данных, но если объем небольшой, преимуществ будет мало или не будет совсем.

На уровне ОС каждый процесс имеет структуру данных, которая называется блок
управления процессом (**Process Control Block**, `РСВ`). `РСВ` использует идентификатор процесса (**Process ID**, `PID`), счетчик команд, регистры ЦП, информацию о планировании ресурсов ЦП и многие другие атрибуты, а также хранит состояние процесса (выполняется или ожидает).

Когда задействуются несколько процессов ЦП, изначально совместного использования памяти нет, а, значит, шанс повреждения данных ниже. Если двум процессам нужен совместным доступ к данным,.им необходим какой-либо механизм взаимодействия между собой. Python поддерживает такое взаимодействие через **примитивы**(Primitive).

### 7.3.2 Создание нескольких процессов

Для многопроцессорного программирования Python предоставляет пакет
`multiprocessing` (аналогичный пакету `multithreading`). Он включает два подхода к реализации многопроцессорной обработки, которые используют объект `Process` и
объект `Pool`.

**Использование объекта `Process`**

Процессы могут быть реализованы с помощью создания объекта `Process`, а затем
использования его метода `start`, аналогичного методу `start` для запуска объекта
`Thread`. Фактически, объект `Process` предлагает тот же `API`, что и объект `Thread`. Простой пример создания нескольких дочерних процессов показан ниже:

```Python
import os
from multiprocessing import Process, current_process as cp
from time import sleep


def print_hello():
    sleep(2)
    print(f'{os.getpid()}-{cp().name}: Hello')


def print_message(msg):
    sleep(1)
    print(f'{os.getpid()}-{cp().name}: {msg}')


def main():
    processes = []

    # создание процессов
    processes.append(Process(target=print_hello, name="Process #1"))
    processes.append(Process(target=print_hello, name="Process #2"))
    processes.append(Process(target=print_message, args=['Good morning'], name="Process #3"))

    # запуск процессов
    for p in processes:
        p.start()

    # ждем завершения всех процессов
    for p in processes:
        p.join()

    print('Exiting the main process')


if __name__ == '__main__':
    main()
```

**Использование объекта `Pool`**

Объект `Pool` предлагает удобный способ (с помощью метода `map`) создания процессов, назначения им функций и распределения входных параметров по процессам.

```Python
import os
from multiprocessing import Process, Pool, current_process as cp
from time import sleep


def print_message(msg):
    sleep (1)
    print(f'{os.getpid()}-{cp().name}: {msg}')


def main ():
    #создаем процесс из пула
    with Pool(3) as proc:
        proc.map(print_message, ["Orange", "Apple", "Banana", "Grapes", "Pears"])
        print("Exiting the main process")


if __name__ == '__main__':
    main()
```

Распределение входных параметров функции, которая привязана к набору процессов
пула, осуществляется методом `map`. Он ожидает завершения выполнения всех
функций, поэтому нет необходимости использовать `join`, если процессы создаются
с помощью объекта `Pool`.

**Сравнение объектов `Pool` и `Process`**

| Использование объекта `Pool` | Использование объекта `Process` |
| --- | --- |
| В памяти остаются только активные процессы | В памяти остаются все созданные процессы |
| Лучше работает с большими наборами данных и повторяющимися задачами | Лучше работает с малыми наборами данных |
| Процессы при вводе-выводе блокируются, пока не будет предоставлен ресурс ввода-вывода | Процессы при вводе-выводе не блокируются |

### 7.3.3 Обмен данными между процессами

Пакет `multiprocessing` предлагает два способа обмена данными между процессами:
**общая память** и **серверный процесс**:

**Использование общих объектов `ctype`(общая память)**

![[Pasted image 20231213152842.png]]

В этом случае создается блок общей памяти, и процессы имеют к нему доступ.
Блок создается при инициализации одного из типов данных `ctype`, доступных в пакете `multiprocessing`. Ими являются `Array`(массив `ctype`) и `Value`(универсальный объект `ctype`). Оба типа выделяются из общей памяти. 

Создать массив `ctype` можно следующим оператором:

```Python
mylist = multiprocessing.Array('i', 5)
```

Он создаст массив с типом данных `integer` и размером `5`. Литерал `i` - это код типа,
в данном случае обозначает `integer`(целое число). Для типа данных `float` используется код `d`. Также можно инициализировать массив, передав последовательность в качестве второго аргумента вместо размера:

```Python
mylist = multiprocessing.Array('i', [1,2,3,4,5))
```

Создать объект `Value` можно следующим способом:

```Python
obj = multiprocessing.Value('i')
```

Будет создан объект `integer`, поскольку указан код `i`. Значение объекта можно задать с помощью атрибута `value`.

Оба объекта `ctype` имеют опциональный аргумент `Lock` со значением `True` по умолчанию. При значении `True` этот аргумент используется для создания нового рекурсивного объекта блокировки, который предоставляет синхронизированный доступ к значениям объектов. При значении `False` защита отключена, и процесс будет небезопасным. Если процесс обращается к общей памяти только для чтения, параметру `Lock` можно установить `False`. В дальнейших примерах кода мы оставим для аргумента `Lock` значение по умолчанию `True`.

**Использование серверного процесса**

В этом случае серверный процесс запускается сразу после старта программы
Python. Он используется для создания и управления новыми дочерними процессами,
запрошенными родительским процессом. Серверный процесс может содержать
объекты Python, к которым другие процессы могут обращаться через прокси.

Для реализации серверного процесса и совместного использования объектов пакет
`multiprocessing` предоставляет объект `Manager`. Он поддерживает разные типы данных

![[Pasted image 20231213153401.png]]

Пример кода, создает объект `dictionary` с помощью объекта `Manager`, а затем передает словарь дочерним процессам для вставки дополнительных данных и вывода содержимого. Для нашего примера мы создадим три дочерних процесса: два для вставки данных в объект словаря и один для получения содержимого словаря для вывода на консоль.

```Python
import multiprocessing
from multiprocessing import Process, Manager


def insert_data(dict1, code, subject):
    dict1[code] = subject


def output(dict1):
    print("Dictionary data: ", dict1)


def main():
    with Manager() as mgr:
        #создаем словарь в серверном процессе
        mydict = mgr.dict({100: "Maths", 200: "Science"})
        p1 = Process(target=insert_data, args=(mydict, 300, "English"))
        р2 = Process(target=insert_data, args=(mydict, 400, "French"))
        рЗ = Process(target=output, args=(mydict,))

        p1.start()
        р2.start()

        p1.join()
        р2.join()

        рЗ.start()
        рЗ.join()


if __name__ == '__main__':
    main()
```

Серверный процесс обеспечивает больше гибкости, чем использование общей памяти, поскольку он поддерживает огромное разнообразие типов объектов. Однако
этот способ имеет низкую производительность по сравнению с общей памятью.

