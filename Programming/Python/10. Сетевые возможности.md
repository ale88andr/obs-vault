![[Pasted image 20230710094729.png]]
## 10.1 HTTP

### 10.1.1 HTTP

HTTP (англ. HyperText Transfer Protocol - «протокол передачи гипертекста») - протокол прикладного уровня передачи данных, изначально - в виде гипертекстовых документов (то есть документов, которые могут содержать ссылки, позволяющие организовать переход к другим документам) в формате HTML, в настоящее время используется для передачи произвольных данных.

Основой HTTP является технология «клиент-сервер», то есть предполагается существование:
- Потребителей (клиентов), которые инициируют соединение и посылают запрос;
- Поставщиков (серверов), которые ожидают соединения для получения запроса, производят необходимые действия и возвращают обратно сообщение с результатом.

HTTP используется также в качестве «транспорта» для других протоколов прикладного уровня, таких как SOAP, XML-RPC, WebDAV.

HTTP - протокол прикладного уровня; аналогичными ему являются FTP и SMTP. Обмен сообщениями идёт по обыкновенной схеме «запрос-ответ». Для идентификации ресурсов HTTP использует глобальные URI. В отличие от многих других протоколов, HTTP **не сохраняет своего состояния** (stateless). Это означает отсутствие сохранения промежуточного состояния между парами «запрос-ответ».

Большинство протоколов предусматривает установление TCP-сессии, в ходе которой один раз происходит авторизация, и дальнейшие действия выполняются в контексте этой авторизации. HTTP же устанавливает **отдельную TCP-сессию на каждый запрос**. Для поддержки авторизованного (неанонимного) доступа в HTTP используются cookies; причем такой способ авторизации позволяет сохранить сессию даже после перезагрузки клиента и сервера.

**Структура HTTP-сообщения**

Каждое HTTP-сообщение состоит из трёх частей, которые передаются в указанном порядке:

- 1. **Стартовая строка** (англ. Starting line) - определяет тип сообщения, различается для запроса и ответа;
- 2. **Заголовки** (англ. Headers) - характеризуют тело сообщения, параметры передачи и прочие сведения;
- 3. **Тело сообщения** (англ. Message Body) - непосредственно данные сообщения. Обязательно должно отделяться от заголовков пустой строкой.

**Стартовая строка**:

Стартовая строка **запроса** выглядит так: _Метод URI HTTP/Версия_, где:
    - Метод (англ. Method) - тип запроса, одно слово заглавными буквами;
    - URI определяет путь к запрашиваемому документу;
    - Версия (англ. Version) - пара разделенных точкой цифр. Например: 1.1.
    
Чтобы запросить страницу данной статьи, клиент должен передать строку (задан всего один заголовок):  

```
GET /wiki/HTTP HTTP/1.1
Host: ru.wikipedia.org  
``` 

Стартовая строка **ответа** сервера имеет следующий формат: _HTTP/Версия КодСостояния Пояснение_, где:
- Версия - пара разделенных точкой цифр, как в запросе;
- Код состояния (англ. Status Code) - три цифры. По коду состояния определяется дальнейшее содержимое сообщения и поведение клиента;
- Пояснение (англ. Reason Phrase) - текстовое короткое пояснение к коду ответа для пользователя. Никак не влияет на сообщение и является необязательным.    

Например, стартовая строка ответа сервера на предыдущий запрос может выглядеть так:

```
HTTP/1.0 200 OK
```   

**Заголовки** 

Заголовки HTTP (англ. HTTP Headers) - это строки в HTTP-сообщении, содержащие разделённую двоеточием пару параметр-значение. Формат заголовков соответствует общему формату заголовков текстовых сетевых сообщений ARPA (см. RFC 822). Заголовки должны отделяться от тела сообщения хотя бы одной пустой строкой. Примеры заголовков:
- Server: Apache/2.2.11 (Win32) PHP/5.3.0
- Last-Modified: Sat, 16 Jan 2010 21:16:42 GMT
- Content-Type: text/plain; charset=windows-1251
- Content-Language: ru

В примере выше каждая строка представляет собой один заголовок. При этом то, что находится до двоеточия, называется именем (англ. name), а что после него - значением (англ. value).

Все заголовки разделяются на четыре основных группы:
- General Headers («Основные заголовки») - могут включаться в любое сообщение клиента и сервера;
- Request Headers («Заголовки запроса») - используются только в запросах клиента;
- Response Headers («Заголовки ответа») - только для ответов от сервера;
- Entity Headers («Заголовки сущности») - сопровождают каждую сущность сообщения.

Именно в таком порядке рекомендуется посылать заголовки получателю.

>Как сервер узнает, с какого типа устройства/браузера/ОС/языка вы открываете веб-сайт (Например, для Adaptive design): когда вы отправляете HTTP-запрос, он содержит в себе заголовки (headers) с различной информацией. Одним из них является User-Agent. Он сообщает: браузер, его версию и язык, движок браузера, версию движка, операционную систему.

**Тело сообщения**

Тело HTTP-сообщения (message-body), если оно присутствует, используется для передачи тела объекта, связанного с запросом или ответом. Тело сообщения отличается от тела объекта (entity-body) только в том случае, когда применяется кодирование передачи, что указывается полем заголовка Transfer-Encoding.

Поле Transfer-Encoding должно использоваться для указания любого кодирования передачи, примененного приложением в целях гарантирования безопасной и правильной передачи сообщения. Поле Transfer-Encoding - это свойство сообщения, а не объекта, и, таким образом, может быть добавлено или удалено любым приложением в цепочке запросов/ответов.

Присутствие тела сообщения в запросе отмечается добавлением к заголовкам запроса поля заголовка Content-Length или Transfer-Encoding. Тело сообщения может быть добавлено в запрос, только когда метод запроса допускает тело объекта.

Включается или не включается тело сообщения в сообщение ответа - зависит как от метода запроса, так и от кода состояния ответа. Все ответы на запрос с методом HEAD не должны включать тело сообщения, даже если присутствуют поля заголовка объекта (entity-header), заставляющие поверить в присутствие объекта. Никакие ответы с кодами состояния 1xx (Информационные), 204 (Нет содержимого, No Content), и 304 (Не модифицирован, Not Modified) не должны содержать тела сообщения. Все другие ответы содержат тело сообщения, даже если оно имеет нулевую длину.

**Методы HTTP**

Метод HTTP - последовательность из любых символов, кроме управляющих и разделителей, указывающая на основную операцию над ресурсом. Обычно метод представляет собой короткое английское слово, записанное заглавными буквами. 

Сервер может использовать любые методы, не существует обязательных методов для сервера или клиента, кроме того, программист может связать метод и выполняемую функцию как угодно его фантазии. Во избежание хаоса существуют соглашения (тот же REST) и стандарты. Формально если сервер не распознал указанный клиентом метод, то он должен вернуть статус 501 (Not Implemented). Если серверу метод известен, но он неприменим к конкретному ресурсу, то возвращается сообщение с кодом 405 (Method Not Allowed). В обоих случаях серверу следует включить в сообщение ответа заголовок Allow со списком поддерживаемых методов.

Основными и чаще всего используемыми методами являются **GET, POST, PUT, DELETE** которые эквивалентны базовым функциям при работе с БД или любыми хранимыми вычислительными сущностями - [CRUD](https://ru.wikipedia.org/wiki/CRUD) (create, read, update, delete).

- **OPTIONS**: Используется для определения возможностей веб-сервера или параметров соединения для конкретного ресурса. В ответ серверу следует включить заголовок Allow со списком поддерживаемых методов. Также в заголовке ответа может включаться информация о поддерживаемых расширениях.

- **GET**: Используется для запроса содержимого указанного ресурса. С помощью метода GET можно также начать какой-либо процесс. В этом случае в тело ответного сообщения следует включить информацию о ходе выполнения процесса. Клиент может передавать параметры выполнения запроса в URI целевого ресурса после символа «?»: `GET /path/resource?param1=value1&param2=value2 HTTP/1.1`. Согласно стандарту HTTP, запросы типа GET считаются идемпотентными(*повторный идентичный запрос, сделанный один или несколько раз подряд, имеет один и тот же эффект, не изменяющий состояние сервера*). 

- **HEAD**: Аналогичен методу GET, за исключением того, что в ответе сервера отсутствует тело. Запрос HEAD обычно применяется для извлечения метаданных, проверки наличия ресурса (валидация URL) и чтобы узнать, не изменился ли он с момента последнего обращения. Заголовки ответа могут кэшироваться. При несовпадении метаданных ресурса с соответствующей информацией в кэше - копия ресурса помечается как устаревшая;

- **POST**: Применяется для передачи пользовательских данных заданному ресурсу. Например, в блогах посетители обычно могут вводить свои комментарии к записям в HTML-форму, после чего они передаются серверу методом POST и он помещает их на страницу. При этом передаваемые данные (в примере с блогами - текст комментария) включаются в тело запроса. Аналогично с помощью метода POST обычно загружаются файлы на сервер. В отличие от метода GET, метод POST не считается идемпотентным, то есть многократное повторение одних и тех же запросов POST может возвращать разные результаты (например, после каждой отправки комментария будет появляться очередная копия этого комментария). При результате выполнения `200 (Ok)` в тело ответа следует включить сообщение об итоге выполнения запроса. Если был создан ресурс, то серверу следует вернуть ответ `201 (Created)` с указанием URI нового ресурса в заголовке `Location`. Сообщение ответа сервера на выполнение метода POST не кэшируется.

- **PUT**: Применяется для загрузки содержимого запроса на указанный в запросе URI. Если по заданному URI не существует ресурса, то сервер создаёт его и возвращает статус `201 (Created)`. Если же ресурс был изменен, то сервер возвращает `200 (Ok)` или `204 (No Content)`. Фундаментальное различие методов **POST** и **PUT** заключается в понимании предназначений URI ресурсов. Метод **POST** предполагает, что по указанному URI будет производиться обработка передаваемого клиентом содержимого. Используя **PUT**, клиент предполагает, что загружаемое содержимое соответствует находящемуся по данному URI ресурсу. Сообщения ответов сервера на метод **PUT** не кэшируются;

- **PATCH**: Аналогично PUT, но применяется только к фрагменту ресурса;

- **DELETE**: Удаляет указанный ресурс;

- **TRACE**: Возвращает полученный запрос так, что клиент может увидеть, какую информацию промежуточные серверы добавляют или изменяют в запросе;

- **CONNECT**: Преобразует соединение запроса в прозрачный TCP/IP-туннель, обычно чтобы содействовать установлению защищенного SSL-соединения через нешифрованный прокси.

**Различия методов GET и POST**

Основное состоит в способе передачи данных веб-формы обрабатывающему скрипту, а именно:
- Метод GET отправляет скрипту всю собранную информацию формы как часть URL: http://www.komtet.ru/script.php?login=admin&name=komtet
- Метод POST передает данные таким образом, что пользователь сайта уже не видит передаваемые скрипту данные: http://www.komtet.ru/script.php

Кроме того:
- Количество информации, передаваемой методом GET через URL строку ограничено 2048 символами (минус служебная информация браузера);
- Страницу, сгенерированную методом GET, можно добавить в закладки и поделиться ссылкой;
- Чуствительные данные передаваемые через GET в таком открытом виде очевидно плохо влияют на безопасность;
- Метод POST в отличие от метода GET позволяет передавать запросу файлы;
- При использовании метода GET существует риск того, что поисковый робот может выполнить тот или иной открытый запрос.

**Коды состояния**

Код состояния является частью первой строки ответа сервера. Он представляет собой целое число из трёх цифр. Первая цифра указывает на **класс состояния**. За кодом ответа обычно следует отделенная пробелом **поясняющая фраза** на английском языке, которая разъясняет причину именно такого ответа. Примеры:
- 201 Webpage Created;
- 403 Access allowed only for registered users;
- 507 Insufficient Storage.

Клиент узнаёт по коду ответа о результатах его запроса и определяет, какие действия ему предпринимать дальше. Набор кодов состояния является стандартом, и они описаны в соответствующих документах RFC.

В настоящее время выделено пять классов кодов состояния.

|**Код**|**Класс**|**Назначение**|
|---|---|---|
|100-е (1ХХ)|Информационный (англ. informational)|Информирование о процессе передачи.В HTTP/1.0 - сообщения с такими кодами должны игнорироваться.В HTTP/1.1 - клиент должен быть готов принять этот класс сообщений как обычный ответ, но ничего отправлять серверу не нужно.Сами сообщения от сервера содержат только стартовую строку ответа и, если требуется, несколько специфичных для ответа полей заголовка. Прокси-серверы подобные сообщения должны отправлять дальше от сервера к клиенту.|
|200-е (2ХХ)|Успех (англ. Success)|Информирование о случаях успешного принятия и обработки запроса клиента. В зависимости от статуса, сервер может ещё передать заголовки и тело сообщения.|
|300-е (3ХХ)|Перенаправление (англ. Redirection)|Сообщает клиенту, что для успешного выполнения операции необходимо сделать другой запрос (как правило по другому URI). Из данного класса пять кодов 301, 302, 303, 305 и 307 относятся непосредственно к перенаправлениям (редирект). Адрес, по которому клиенту следует произвести запрос, сервер указывает в заголовке Location. При этом допускается использование фрагментов в целевом URI.|
|400-е (4ХХ)|Ошибка клиента (англ. Client Error)|Указание ошибок со стороны клиента. При использовании всех методов, кроме HEAD, сервер должен вернуть в теле сообщения гипертекстовое пояснение для пользователя.|
|500-е (5ХХ)|Ошибка сервера(англ. Server Error)|Информирование о случаях неудачного выполнения операции по вине сервера. Для всех ситуаций, кроме использования метода HEAD, сервер должен включать в тело сообщения объяснение, которое клиент отобразит пользователю.|

**Отличия HTTP/1.1 от HTTP/2.0**

11 февраля 2015 года опубликованы финальные версии черновика следующей версии протокола. В отличие от предыдущих версий, протокол HTTP/2 является бинарным. Среди ключевых особенностей: мультиплексирование запросов, расстановка приоритетов для запросов, сжатие заголовков, загрузка нескольких элементов параллельно посредством одного TCP-соединения, поддержка проактивных push-уведомлений со стороны сервера.

### 10.1.2 **HTTPS**

У HTTP есть один недостаток: данные передаются в открытом виде и никак не защищены. На пути из точки А в точку Б информация в интернете проходит через десятки промежуточных узлов, и, если хоть один из них находится под контролем злоумышленника, данные могут перехватить. То же самое может произойти, когда вы пользуетесь незащищенной сетью Wi-Fi, например, в кафе. Для установки безопасного соединения используется протокол HTTPS с поддержкой шифрования.

HTTPS (аббр. от англ. HyperText Transfer Protocol Secure) - расширение протокола HTTP для поддержки шифрования в целях повышения безопасности. Данные в протоколе HTTPS передаются поверх криптографических протоколов TLS или устаревшего в 2015 году SSL.

HTTPS не является отдельным протоколом. Это обычный HTTP, работающий через шифрованные транспортные механизмы SSL и TLS. Он обеспечивает защиту от атак, основанных на прослушивании сетевого соединения - от снифферских атак и атак типа man-in-the-middle, при условии, что будут использоваться шифрующие средства и сертификат сервера проверен и ему доверяют.

По умолчанию HTTPS URL использует 443 TCP-порт (для незащищенного HTTP - 80). Чтобы подготовить веб-сервер для обработки https-соединений, администратор должен получить и установить в систему сертификат открытого и закрытого ключа для этого веб-сервера. В TLS используется как асимметричная схема шифрования (для выработки общего секретного ключа), так и симметричная (для обмена данными, зашифрованными общим ключом). Сертификат открытого ключа подтверждает принадлежность данного открытого ключа владельцу сайта. Сертификат открытого ключа и сам открытый ключ посылаются клиенту при установлении соединения; закрытый ключ используется для расшифровки сообщений от клиента.

Существует возможность создать такой сертификат, не обращаясь в центр сертификации. Подписываются такие сертификаты этим же сертификатом и называются самоподписанными (self-signed). Без проверки сертификата каким-то другим способом (например, звонок владельцу и проверка контрольной суммы сертификата) такое использование HTTPS подвержено атаке посредника.

Эта система также может использоваться для аутентификации клиента, чтобы обеспечить доступ к серверу только авторизованным пользователям. Для этого администратор обычно создает сертификаты для каждого пользователя и загружает их в браузер каждого пользователя. Также будут приниматься все сертификаты, подписанные организациями, которым доверяет сервер. Такой сертификат обычно содержит имя и адрес электронной почты авторизованного пользователя, которые проверяются при каждом соединении, чтобы проверить личность пользователя без ввода пароля.

В HTTPS для шифрования используется длина ключа 40, 56, 128 или 256 бит. Многие современные сайты требуют использования новых версий браузеров, поддерживающих шифрование с длиной ключа 128 бит, с целью обеспечить достаточный уровень безопасности. Шифрование с длиной ключа 128 бит значительно затрудняет подбор паролей и доступ к личной информации.

Традиционно на одном IP-адресе может работать только один HTTPS-сайт. Для работы нескольких HTTPS-сайтов с различными сертификатами применяется расширение TLS под названием Server Name Indication (SNI).

Идентификация в HTTPS:
- Идентификация сервера: HTTP/TLS запросы генерируются путём разыменования URI, вследствие чего имя хоста становится известно клиенту. В начале общения, сервер посылает клиенту свой сертификат, чтобы клиент идентифицировал его. Это позволяет предотвратить атаку посредника. В сертификате указывается URI сервера. Согласование имени хоста и данных, указанных в сертификате, происходит в соответствии с протоколом RFC2459. Если имя сервера не совпадает с указанным в сертификате, то пользовательские программы, например браузеры, сообщают об этом пользователю. В основном, браузеры предоставляют пользователю выбор: продолжить незащищённое соединение или прервать его.
- Идентификация клиента: Обычно сервер не располагает информацией о клиенте, достаточной для его идентификации. Однако для обеспечения повышенной защищенности соединения используется так называемая two-way authentication. При этом сервер после подтверждения его сертификата клиентом также запрашивает сертификат. Таким образом, схема подтверждения клиента аналогична идентификации сервера.

---

![[Pasted image 20231222145313.png]]

Безопасный протокол передачи гипертекста (`HTTPS`) является расширением протокола передачи гипертекста (`HTTP`). `HTTPS` передает зашифрованные данные с использованием безопасного транспортного уровня (`TLS`). Если данные перехвачены в Интернете, все, что получает злоумышленник — это двоичный код.

**Как шифруются и расшифровываются данные?**

1. Клиент (браузер) и сервер устанавливают `TCP-соединение`.
2. Клиент отправляет серверу `«client hello»`. Сообщение содержит набор необходимых алгоритмов шифрования (наборов шифров) и последнюю поддерживаемую версию `TLS`. Сервер отвечает `«server hello»`, чтобы браузер знал, может ли он поддерживать данные алгоритмы и версию `TLS`. Затем сервер отправляет сертификат `SSL` клиенту. Сертификат содержит **открытый ключ**, имя хоста, дату истечения срока действия и т. д. Клиент проверяет сертификат.
3. После проверки сертификата `SSL` клиент генерирует **сеансовый ключ** и шифрует его с помощью **открытого ключа**. Сервер получает зашифрованный **сеансовый ключ** и расшифровывает его с помощью **закрытого ключа**.
4. Теперь, когда и клиент, и сервер имеют один и тот же **сеансовый ключ** (симметричное шифрование), зашифрованные данные передаются по защищенному двунаправленному каналу.

**Почему HTTPS переключается на симметричное шифрование при передаче данных?** 

Есть две основные причины:
1. **Безопасность**. Асимметричное шифрование работает только в одном направлении. Это означает, что если сервер попытается отправить зашифрованные данные обратно клиенту, любой сможет расшифровать данные с помощью открытого ключа.
2. **Ресурсы сервера**. Асимметричное шифрование добавляет довольно много математических операций. Оно не подходит для передачи данных в длительных сеансах.

### 10.1.3 Сеансы HTTP

Любому веб-сайту, требуется установить с пользователем **сеанс HTTP** (**HTTP session**). Веб-приложению требуется знать, от кого из пользователей пришел запрос, при каких условиях он был совершен и каковы параметры учетной записи посетителя. Это необходимо для совершения буквально любой операции. Когда вы покупаете на Amazon, пишете на Facebook либо переводите кому-то деньги, серверу нужно знать, какой из всех запросов принадлежит именно вам.

Допустим, Алиса впервые заходит на Википедию, и, следовательно, в запросе нет идентификатора сеанса. Энциклопедия замечает это, создает новый и сохраняет его у себя на сервере. Затем с ответом Википедия посылает новенький идентификатор Алисе. Браузер Алисы запоминает его и отправляет вместе с каждым последующим
запросом. Википедия видит в разных запросах одинаковый идентификатор и понимает, что все они принадлежат одному сеансу. Пусть Боб тоже впервые открыл для себя Википедию. Энциклопедия тоже создаст ему уникальный идентификатор сеанса и отправит вместе с ответом. Браузер Боба будет прикреплять этот идентификатор к каждому последующему запросу. Таким образом Википедия может различать запросы Алисы и Боба между собой, как показано на рис.
![[Pasted image 20230816100005.png]]
Вести учет пользовательских сеансов – непростая задача. Существуют несколько способов, каждый из них имеет свои плюсы и минусы, но все они зависят от **cookie**.
#### HTTP cookie

Браузеры организованно хранят небольшие строки под названием **cookie** (**ку́ки**). Они могут быть созданы вручную пользователем, но, как правило, их присылает сервер вместе с ответом на запрос. Браузер отправляет их обратно вместе с каждым последующим запросом. Идентификатор сеанса также передается с помощью **cookie**. При создании нового сеанса сервер отправляет его идентификатор именно через **cookie** с помощью заголовка ответа **Set-Cookie**. **Сookie** содержат в себе **имя и значение.** По умолчанию `Django` называет хранящие идентификатор сеанса cookie **sessionid**:

```
Set-Cookie: sessionid=<cookie-value>
```

Для отправки **cookie** обратно на сервер применяется заголовок **Cookie**. Он содержит их имена и значения, разделенные точкой с запятой. Каждая пара ключ-значение – отдельный файл **cookie**. Вот, например, выдержка из запроса к веб-приложению на `Django`. Он содержит в себе два **cookie**:

```
Cookie: sessionid=cgqbyjpxaoc5x5mmm9ymcqtsbp7w7cn1; key=value
Host: django-web-app.com
...
```

**Сookie**, присланные с заголовком **Set-Cookie**, могут содержать некоторые дополнительные атрибуты. С их помощью можно несколько обезопасить cookie идентификатора сеанса.

- Атрибут **Secure** - Сервер может противостоять прослушке cookie, снабдив ее атрибутом `Secure`

```
Set-Cookie: sessionid=<session-id-value>; Secure
```

> Атрибуты перечисляются через точку с запятой. Стоит заметить, что каждый cookie отправляется сервером в отдельном заголовке Set-Cookie. Таким образом, в ответе сервера может содержаться несколько заголовков Set-Cookie. Браузер же отправляет их обратно, перечисляя все сразу через точку с запятой в одном заголовке Cookie.

Атрибут `Secure` запрещает браузеру отправлять **cookie** обратно по HTTP и предписывает делать это только по HTTPS.

> За присвоение этого атрибута cookie идентификатора сеанса в Django отвечает булева настройка SESSION_COOKIE_SECURE. Изначально она задана в False.

- Атрибут **Domain** - Сервер использует этот атрибут, чтобы указать, на какие из подсайтов cookie должен быть отправлен обратно:

```
Set-Cookie: sessionid=<session-id-value>; Domain=django-web-app.com
```

Допустим,` django-web-app.com` не указывает у cookie атрибут `Domain`. В таком
случае он будет отправлен обратно на `django-web-app.com`, но не будет отправлен на `sub.django-web-app.com`. Пусть атрибут `Domain` будет указан как `django-web-app.com`. Тогда cookie будет отправлен не только `django-web-app.com`, но и при запросе ресурсов с `sub.django-web-app.com`.

Настройка `SESSION_COOKIE_DOMAIN` отвечает за указание атрибута. По умолчанию стои́т `None`, поэтому атрибут `Domain` не задается. Настройке можно присвоить строку с доменным именем, как то `django-web-app.com`:

```
SESSION_COOKIE_DOMAIN = "django-web-app.com"
```

- Атрибут **Max-Age** - Сервер добавляет атрибут **Max-Age**, чтобы задать срок действия cookie.

```
Set-Cookie: sessionid=<session-id-value>; Max-Age=1209600
```

Как только срок истечет, браузер перестанет отсылать cookie вместе с запросами.
Веб-сервисы вроде электронной почты помнят вас даже спустя какое-то время и не требуют вводить пароль. Но если не заходить на сайт достаточно долго, то учетные данные придется ввести. Причина может быть в том, что срок действия cookie с идентификатором сеанса, как и самого сеанса, истек.

Срок действия **cookie** идентификатора сеанса задает настройка `SESSION_COOKIE_AGE`. Ее изначальное значение – `1 209 600` секунд, то есть две недели.

Если у **cookie** отсутствуют атрибуты `Max-Age` и `Expires`, браузер будет хранить **cookie** в течение всего времени, пока он запущен, и удалит его при закрытии программы.

Если выставить настройку `SESSION_EXPIRE_AT_BROWSER_CLOSE` в `True`, атрибуты `Max-Age` и `Expires` не будут добавлены к cookie идентификатора сеанса, и удален он будет только с закрытием браузера – то есть неизвестно когда. По умолчанию настройка выключена.

## 10.2 Requests

Модуль `Requests` предоставляет возможность управления HTTP-запросами при помощи языка Python. Инструментарий библиотеки широкий и рассчитан на все случаи взаимодействия с web-приложениями.

**Основные возможности библиотеки Requests**

Модуль разработан с учетом потребностей современных web-разработчиков и актуальных технологий. Многие операции автоматизированы, а ручные настройки сведены к минимуму.
- поддержка постоянного HTTP-соединения и его повторное использование;  
- применение международных и национальных доменов;  
- использование **Cookie**: передача и получение значений в формате **ключ: значение**;  
- автоматическое декодирование контента;  
- **SSL** верификация;  
- аутентификация пользователей на большинстве ресурсов с сохранением;  
- поддержка proxy при необходимости;  
- загрузка и выгрузка файлов;  
- стриминговые загрузки и фрагментированные запросы;  
- задержки соединений;  
- передача требуемых заголовков на web-ресурсы и др.

Важно понимать, что `Requests` **не предназначен для парсинга ответа сервера** (для этого применяют другие модули, например, **Beautiful Soup**).

**Первичная настройка и начало работы**

Эта команда установит `Requests` и дополнительные зависимые модули.

```Shell
pip install requests # Для Windows
pip3 install requests # Для Linux, MacOS
```

Чтобы проверить, что все прошло успешно, сделаем простой **GET** запрос на сайт https://github.com.

```Python
>>> import requests
>>> response = requests.get('https://github.com')
>>> response
<Response [200]>
```

Никаких ошибок не получено, следовательно, запрос прошел успешно. Ответ от сервера сохраняем в объект response. В нем содержится вся необходимая информация для анализа, которую нам предоставил сервис. Рассмотрим основные атрибуты данного объекта

```Python
dir(response)
[…, 'apparent_encoding', 'close', 'connection', 'content', 'cookies', 'elapsed', 'encoding', 'headers', 'history', 'is_permanent_redirect', 'is_redirect', 'iter_content', 'iter_lines', 'json', 'links', 'next', 'ok', 'raise_for_status', 'raw', 'reason', 'request', 'status_code', 'text', 'url']
```

Атрибут `headers` - Свойство позволяет просмотреть заголовки ответа сервера: его тип, дату обращения, формат содержимого, кодировку и др.

```Python
response.headers

{'Server': 'GitHub.com', 'Date': 'Fri, 21 Jul 2023 10:59:14 GMT', 'Content-Type': 'text/html; charset=utf-8', ... }
```

Атрибуты: `status_code`, `ok` - Свойства позволяет просмотреть Коды HTTP-ответов и проверить статус ответа, мы можем по-разному реагировать исходя из этого. 

```Python
response.status_code # 200
response.ok          # True
```

Атрибуты: `url`, `request` -  свойства предоставляют информацию о методе запроса (GET, POST и др.) и запрашиваемой ссылке со всеми дополнительными параметрами.

```Python
response.request  # <PreparedRequest [GET]>
response.url      # 'https://github.com/'
```

Атрибуты: `text, content, json` - свойство `text` показывает тело ответа сервера в текстовом формате (актуально для html-страниц), `content` – результат в виде байтов (удобно при скачивании графической, аудио- или видеоинформации), метод `json()` приводит содержимое ответа к обычному словарю (если данные к нему приводимы, в противном случае будет ошибка, как в примере; актуально для API-запросов).

```Python
>>> response.text
'\n\n\n\n\n<!DOCTYPE html>\n<html lang="en"  class="html-fluid">\n  <head>\n	<meta charset="utf-8">\n  <link rel="dns-prefetch" href="https://github.githubassets.com">\n  <link rel="dns-prefetch" href="https://user-images.githubusercontent.com/">…
>>> response.content
b'\n\n\n\n\n<!DOCTYPE html>\n<html lang="en"  class="html-fluid">\n  <head>\n	<meta charset="utf-8">\n  <link rel="dns-prefetch" href="https://github.githubassets.com">\n  <link rel="dns-prefetch" href="https://avatars.githubusercontent.com">…
>>> response.json()
Error…
```

Для получения содержимого web-страницы используется метод GET, работу которого мы показали выше. Библиотека Requests позволяет обращаться к сервисам с помощью других запросов, если они разрешены на сервере. Чтобы полноценно продемонстрировать его работу, разработчики библиотеки создали специальный сайт https://httpbin.org/, на котором можно их опробовать.
![[Pasted image 20230721141326.png]]

1. Метод OPTIONS  

С помощью данного метода мы увидим принимаемые ресурсом или конкретным его разделом HTTP-запросы (просмотр опций включен не у всех ресурсов).  

Пример – Интерактивный режим  

```Python
>>> response = requests.options('https://httpbin.org/')
>>> response.headers['Access-Control-Allow-Methods']
GET, POST, PUT, DELETE, PATCH, OPTIONS
```

Как видим, на сайте имеется возможность протестировать практически все виды HTTP-запросов.  

2. Метод GET  

У **GET-запросов** могут присутствовать параметры, которыми легко управлять. Например: **https://site.ru/?text=python&lang=ru** (ищем сайты про Python на русском языке на некоем условном поисковике). Для этого есть именованный аргумент **params**. Предположим, требуется **11** страница в категории автомобили.  

Пример – Интерактивный режим  

```Python
>>> get_params = {'page': 11, 'product': 'car'}
>>> response = requests.get('https://httpbin.org/', params=get_params)
>>> response.url
'https://httpbin.org/?page=11&product=car'
```

Ссылка успешно сформирована и передана на сервис.  

3. Метод POST  

Для отправки данных (например, форм) применяют метод **POST** библиотеки **Requests**. В аргументе **data** указываются все требуемые поля. Ответом будет **json-объект** с переданными данными, а также ряд иных сведений (заголовки, ip-адрес, ссылка).  

Пример – Интерактивный режим  

```Python
>>> post_params = {'user': 'admin', 'password': 'admin_pass1'}
>>> response = requests.post('https://httpbin.org/post', data=post_params)
>>> response.json()['form']
{'password': 'admin_pass1', 'user': 'admin'}
```

4. Метод HEAD  

Аналогичен запросу **GET** по своей сути, но может служить предварительным тестом ресурса, с которого планируется скачивать файл большого размера. Если заголовки получены, то все хорошо и можно приступать к загрузке.  

Пример – Интерактивный режим  

```Python
>>> response = requests.head('https://httpbin.org/')
>>> response.headers
{'Date': 'Sat, 06 Mar 2021 11:40:49 GMT', 'Content-Type': 'text/html; charset=utf-8', 'Content-Length': '9593', 'Connection': 'keep-alive', 'Server': 'gunicorn/19.9.0', 'Access-Control-Allow-Origin': '*', 'Access-Control-Allow-Credentials': 'true'}
```

5. Метод PUT  

Представленный метод является идемпотентным. Это значит, что повторная отправка идентичных данных никак не повлияет на работу ресурса. Если использовать метод **POST**, то возможны ошибки.  

Пример – Интерактивный режим  

```Python
>>> put_params = {'user': 'admin', 'password': 'admin_pass1'}
>>> response = requests.put('https://httpbin.org/put', data=put_params)
>>> response.status_code
200
>>> response = requests.put('https://httpbin.org/', data=put_params)
>>> response.status_code
405
```

В первом случае запрос отработал удачно (о чем говорит код **200**), тогда как во втором – нет (**405** код – неразрешенный метод по указанному адресу).  

6. Метод PATCH  

Предполагает частичное обновление данных на сервере.  

Пример – Интерактивный режим  

```Python
>>> patch_params = {'user': 'new_admin', 'password': 'new_pass'}
>>> response = requests.patch('https://httpbin.org/patch', data=patch_params)
>>> response.status_code
200
```

Чаще всего применяется для изменения содержимого конфигурационных файлов (например, вы поменяли токен для доступа к API).  

7. Метод DELETE  

Когда требуется удаление некоего ресурса.  

Пример – Интерактивный режим  

```Python
>>> del_params = {"name": "Николай", "job": "Повар"}
>>> response = requests.delete('https://httpbin.org/delete', data=del_params)
>>> response.json()['form']
{'job': 'Повар', 'name': 'Николай'}
```

#### Скачивание файлов

**Единовременная загрузка**

```Python
import requests
 
response = requests.get('http://ca.tinkoff.ru/certs/tinkoffca2021.crl')
    with open('tinkoffca2021.crl', 'wb') as file:
        file.write(response.content)
```

**Запись файла частями**

```Python
def download_chunk():
    response = requests.get('http://ca.tinkoff.ru/certs/tinkoffca2021.crl', stream=True)
    with open('tinkoffca2021.crl', 'wb') as file:
        for chunk in response.iter_content(chunk_size=10000):
            if chunk:
                file.write(chunk)
```

Во-первых, мы добавили параметр `stream=True` к методу `get()` . Это гарантирует постепенную загрузку файла, что не позволит переполнять память. Метод `iter_content()` скачивает файл частями (в нашем случае – по 10 Кб). Таким образом, мы «дописываем» файл новыми кусками на каждой итерации, а если связь с сервером будет потеряна, то на ПК останется хотя бы часть файла.

#### Сессии и прокси  

Сайты, особенно высоконагруженные, не очень любят видеть на своих страницах роботов (если они не одобрены, для чего часто внедряют API). Те, кто сталкивался с парсингом ресурсов, могли не раз убедиться, что со временем сервисы закрывают доступ по вашему IP или на основании пересылаемых модулем **Requests** данных. В каждом случае решение проблемы индивидуально. Однако имеются базовые приемы, снижающие вероятность блокировки работы вашего скрипта.

```Python
>>> import requests
>>> response = requests.get('https://www.python.org/')
>>> response.request.headers
{'User-Agent': 'python-requests/2.25.1', 'Accept-Encoding': 'gzip, deflate', 'Accept': '*/*', 'Connection': 'keep-alive'}
```

Строка **response.request.headers** отображает отправляемые нами заголовки на сайт. В качестве юзер-агента указана библиотека **requests**, что не очень хорошо, так как любой нормальный сервис вас сразу же забанит при частых запросах. Его стоит поменять на реальный, как у «живого» человека.

```Python
>>> import requests
>>> user_agent = {'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.72 Safari/537.36'}
>>> response = requests.get('https://www.python.org/', headers=user_agent)
>>> response.request.headers
{'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.72 Safari/537.36', 'Accept-Encoding': 'gzip, deflate', 'Accept': '*/*', 'Connection': 'keep-alive'}
```

Как видим, сервер теперь думает, что мы вошли через браузер Chrome, например. Это не гарантирует отсутствие блокировки, но уменьшает ее шансы.  
  
На практике можно дополнительно пользоваться сессией и прокси-серверами:  

1. Сессии помогают сайту «запоминать» нас (со всеми параметрами), чтобы при каждом новом обращении к нему (отдельным страницам) не отправлять все заголовки заново, с нуля.
2. Прокси подменяют наш IP-адрес на другой, который пока что не находится в «черном списке». Следует понимать, что их использование не всегда имеет негативный оттенок. В частности, они могут ускорять маршрутизацию к ресурсам (которые находятся на другом конце планеты), обходить блокировку отдельных провайдеров или стран (когда требуется посетить ресурс, недоступный через ваш IP).

```Python
>>> import requests
>>> user_agent = {'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.72 Safari/537.36'}
>>> proxy = {'http': 'http://185.253.98.21:3128', 'https': 'http://185.253.98.21:3128'}
>>> response = requests.get('https://ramziv.com/ip')
>>> response.text
29.174.182.126
>>> session = requests.Session()
>>> session.proxies.update(proxy)
>>> session.headers.update(user_agent)
>>> response = session.get('https://ramziv.com/ip')
>>> response.text
185.253.98.21
```

## 10.3 Сокет/веб-сокет (socket/websocket)

**Со́кет** (англ. socket - разъем) - название программного интерфейса для обеспечения обмена данными между процессами. Процессы при таком обмене могут исполняться как на одной ЭВМ, так и на различных ЭВМ, связанных между собой сетью. Сокет - абстрактный объект, представляющий конечную точку соединения.

Следует различать клиентские и серверные сокеты. Клиентские сокеты грубо можно сравнить с конечными аппаратами телефонной сети, а серверные - с коммутаторами. Клиентское приложение (например, браузер) использует только клиентские сокеты, а серверное (например, веб-сервер, которому браузер посылает запросы) - как клиентские, так и серверные сокеты.

**Принципы сокетов**

Для взаимодействия между машинами с помощью стека протоколов TCP/IP используются адреса и порты. Адрес представляет собой 32-битную структуру для протокола IPv4, 128-битную для IPv6. Номер порта - целое число в диапазоне от 0 до 65535 (для протокола TCP).

Эта пара определяет **сокет** («гнездо», соответствующее адресу и порту).

В процессе обмена, как правило, используется два сокета - сокет отправителя и сокет получателя. Например, при обращении к серверу на HTTP-порт сокет будет выглядеть так: `194.106.118.30:80`, а ответ будет поступать на `mmm.nnn.ppp.qqq:xxxxx`.

Каждый процесс может создать «слушающий» сокет (серверный сокет) и привязать его к какому-нибудь порту операционной системы.

Слушающий процесс обычно находится в цикле ожидания, то есть просыпается при появлении нового соединения. При этом сохраняется возможность проверить наличие соединений на данный момент, установить тайм-аут для операции и т. д.

**WebSocket**

**WebSocket** - протокол связи поверх TCP-соединения, предназначенный для обмена сообщениями между браузером и веб-сервером в режиме реального времени.

**Разница Socket и WebSocket**

Socket и WebSocket - это разные понятия в принципе. При работе по протоколу WebSocket вы будете использовать обычные сокеты для соединения. Так же как и при работе с другими протоколами будут использованы сокеты (и для работы с http, с ftp и др.).

Например, рассмотрим строку вида - ws://127.0.0.1:15000. В ней `ws` - это именно указание на то, что при обмене данными будет использован протокол **WebSocket**. `127.0.0.1` - ip адрес компьютера, `15000` - порт, на который производится подключение. Так вот `127.0.0.1:15000` - эта пара, если можно так выразится, и является сокетом.

Протокол **WebSocket** создавался для того, чтобы можно было поддерживать длительные неразрывные соединения между браузером (который является клиентом) и веб-сайтом (который является сервером).

Протокол **WebSocket** не похож на HTTP. Единственное, чем он напоминает HTTP - только одним самым первым запросом на подключение (так называемым рукопожатием/handshake). Это было сделано, потому что изначально протокол рассчитан на работу в браузере и необходимо было определение возможности поддержки его. После того, как соединение установлено, ничего похожего на протокол HTTP в протоколе **WebSocket** даже близко нет. Именно отсутствие каких-либо наворотов в протоколе **WebSocket** и дает ему возможность быстрой работы.

### 10.3.1 Сетевое взаимодействие посредством сокетов, модуль `socket`

**Сокет** – это способ читать и записывать данные по сети.

Чтобы создать сетевое взаимодействие, прежде всего создадим главный сокет, называемый серверным. Он будет принимать сообщения от клиентов, желающих установить с нами соединение. После того как серверный сокет подтвердит запрос на подключение, мы создаем сокет, предназначенный для взаимодействия с клиентом.

Такой сервер можно создать с помощью встроенного в Python модуля `socket` предоставляющего средства для чтения, записи и управления сокетом. Для начала напишем простой сервер, который прослушивает порт, куда поступают запросы на подключение от клиентов, и печатает сообщения об успешном подключении. С этим сокетом будут ассоциированы имя хоста и порт

![[Pasted image 20231219101002.png]]

Для создания сокета нужно выполнить несколько шагов. Сначала с помощью функции `socket` создается сокет:

```Python
import socket

server_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
server_socket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
```

Функция `socket` принимает два параметра. Первый, `socket.AF_INET`, – тип адреса, в данном случае адрес будет содержать имя хоста и номер порта. Второй, `socket.SOCK_STREAM`, означает, что для взаимодействия будет использоваться протокол `TCP`. Мы также вызываем функцию `setsockopt`, чтобы установить флаг
`SO_REUSEADDR` в `1`. Это позволит повторно использовать номер порта, после того как мы остановим и заново запустим приложение, избегнув тем самым ошибки «*Адрес уже используется*».

Функция `socket.socket` создает сокет, но начать взаимодействие по нему мы еще не можем, потому что сокет не привязан к адресу, по которому могут обращаться клиенты.

```Python
server_address = (127.0.0.1, 8000)
server_socket.bind(server_address)
```

Теперь у сокета есть адрес – `127.0.0.1:8000`. Клиенты смогут использовать этот адрес для отправки данных нашему серверу, а если мы отправим данные клиенту, то клиент увидит адрес, с которого они пришли.

Далее мы должны активно прослушивать запросы от клиентов, желающих подключиться к нашему серверу. Для этого вызывается метод сокета `listen`. Затем мы ждем запроса на подключение с помощью метода accept. Этот метод блокирует программу до получения запроса, после чего возвращает объект подключения и адрес подключившегося клиента. Объект подключения – это еще один сокет, который можно использовать для чтения данных от клиента и записи адресованных ему данных.

```Python
server_socket.listen()
connection, client_address = server_socket.accept()
```

Запуск сервера и прослушивание порта для подключения

![[Pasted image 20231219102045.png]]


Теперь, когда сервер, способный принимать запросы на подключение, создан, посмотрим, как читать посылаемые ему данные. В классе `socket` имеется метод `recv`, который позволяет получать данные из сокета. Метод принимает целое число, показывающее, сколько байтов мы хотим прочитать. Это важно, потому что мы не можем прочитать из сокета сразу все данные, а должны сохранять их в буфере,
пока не дойдем до конца.

В данном случае концом считается пара символов: возврат каретки, перевод строки, или `\r\n`. Именно эта пара добавляется в конец строки, когда пользователь нажимает клавишу Enter в `telnet`. Чтобы продемонстрировать, как работает буферизация небольших сообщений, зададим размер буфера заведомо малым. В реальных приложениях нужен буфер побольше, например на `1024` байта. Большой буфер позволит воспользоваться механизмом буферизации на уровне операционной системы, это эффективнее, чем буферизация в приложении.

```Python
import socket


server_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
server_socket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)

server_address = ('127.0.0.1', 8000)
server_socket.bind(server_address)
server_socket.listen()

try:
    connection, client_address = server_socket.accept()
    print(f'Получен запрос на подключение от {client_address}!')
    buffer = b''
    while buffer[-2:] != b'\r\n':
        data = connection.recv(2)
        if not data:
            break
        else:
            print(f'Получены данные: {data}!')
            buffer = buffer + data
    print(f"Все данные: {buffer}")
    connection.sendall(buffer)
finally:
    server_socket.close()
```

Здесь мы ждем запроса на подключение в функции `server_socket.accept`, как и раньше. Получив запрос, мы пытаемся принять два байта и сохранить их в буфере. Затем входим в цикл и на каждой итерации проверяем, заканчивается ли буфер символами возврата каретки и перевода строки. Если нет, то получаем еще два байта, печатаем их и добавляем в буфер. После получения `\r\n` мы выходим из цикла и печатаем все сообщение, полученное от клиента, а затем закрываем
серверный сокет в блоке `finally`. Таким образом, соединение будет гарантированно закрыто, даже если при чтении данных возникнет исключение.

Сейчас это приложение в каждый момент времени обслуживает только одного клиента, но подключиться к одному серверному сокету может несколько клиентов. Изменим код, разрешив одновременное подключение нескольких клиентов. Попутно продемонстрируем, что нормально поддержать несколько клиентов с помощью блокирующих сокетов не получается.

**Разрешение нескольких подключений**

Сокет, находящийся в режиме прослушивания, допускает одновременное подключение нескольких клиентов. Это значит, что при повторном вызове `socket.accept` мы каждый раз будем получать новый клиентский сокет для чтения и записи данных. Будем в бесконечном цикле вызывать `socket.accept` для прослушивания новых подключений. Приняв подключение, добавим его в конец списка имеющихся подключений. Затем в цикле обойдем все подключения, примем из каждого данные и запишем их обратно в сокет, чтобы передать клиенту.

```Python
import socket


server_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
server_socket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)

server_address = ('127.0.0.1', 8000)
server_socket.bind(server_address)
server_socket.listen()

connections = []

try:
    while True:
        connection, client_address = server_socket.accept()
        print(f'Получен запрос на подключение от {client_address}!')
        connections.append(connection)

        for connection in connections:
            buffer = b''

            while buffer[-2:] != b'\r\n':
                data = connection.recv(2)
                if not data:
                    break
                else:
                    print(f'Получены данные: {data}!')
                    buffer = buffer + data
            print(f"Все данные: {buffer}")
            connection.send(buffer)
finally:
    server_socket.close()
```

Можем проверить эту версию. Подключимся с помощью `telnet` и введем сообщение. Затем можно подключиться из второго telnet-клиента и отправить другое сообщение. И тут же наткнемся на проблему. Первый клиент работает и получает копии своих сообщений, как и положено, а вот второй не получает ничего. Связано это с тем, что по умолчанию сокеты блокирующие. Методы `accept` и `recv` блокируют выполнение программы, пока не получат данные. 

Мы написали программу, которая не масштабируется на случай, когда клиентов
больше одного. Эту проблему можно решить, переведя сокеты в неблокирующий режим. Если сокет помечен как неблокирующий, его методы не будут блокировать выполнение программы в ожидании поступления данных.

По сути дела, создание неблокирующего сокета отличается от создания блокирующего только вызовом метода `setblocking` с параметром False. По умолчанию это значение равно True, т. е. сокет блокирующий.

```Python
import socket


server_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
server_socket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)

server_address = ('127.0.0.1', 8000)
server_socket.bind(server_address)
server_socket.listen()
server_socket.setblocking(False)

connections = []

try:
    while True:
        try:
            connection, client_address = server_socket.accept()
            connection.setblocking(False)
            print(f'Получен запрос на подключение от {client_address}!')
            connections.append(connection)
        except BlockingIOError:
            pass

        for connection in connections:
            try:
                buffer = b''

                while buffer[-2:] != b'\r\n':
                    data = connection.recv(2)
                    if not data:
                        break
                    else:
                        print(f'Получены данные: {data}!')
                        buffer = buffer + data
                print(f"Все данные: {buffer}")
                connection.send(buffer)
            except BlockingIOError:
                pass
finally:
    server_socket.close()
```

На каждой итерации бесконечного цикла ни один из вызовов `accept` и `recv` не блокирует выполнение, и мы либо сразу же получаем исключение, которое игнорируем, либо данные, которые обрабатываем. Итерации выполняются быстро, и поведение программы не зависит от того, посылает кто-нибудь данные или нет.

Описанный подход работает, но обходится дорого. Первый недостаток – качество кода. Перехват исключений всякий раз, как не оказывается данных, приводит к многословному и чреватому ошибками коду. Второй – потребление ресурсов. Это приложение постоянно потребляет почти 100 % процессорного времени, поскольку мы выполняем итерации цикла и получаем исключения настолько быстро, насколько позволяет операционная система. В результате в рабочей нагрузке
преобладает потребление процессора.







## 10.4 Frameworks

### 10.4.1 Flask

#TODO 

### 10.4.2 `aiohttp`

#### 10.4.2.1 Введение в `aiohttp`

Начинающие изучать `asyncio` часто сталкиваются с проблемой: взять уже имеющийся код и внести в него `async` и `await` в надежде улучшить производительность. Чаще всего, в частности для веб-запросов, это работать не будет, поскольку большинство существующих библиотек – **блокирующие**.

Популярной библиотекой для работы с веб-запросами является `requests`. Она плохо совместима с `asyncio`, поскольку в ней используются блокирующие сокеты. Это значит, что отправка любого запроса блокирует поток, в котором запрос отправлен, а поскольку `asyncio` **однопоточная**, будет блокирован весь цикл событий, пока запрос не завершится.

Чтобы решить эту проблему и добиться конкурентности, нам нужна библиотека, которая не блокирует ничего вплоть до уровня сокетов. Одной из таких библиотек является `aiohttp`, которая решает проблему с помощью **неблокирующих сокетов**.

`aiohttp` – библиотека с открытым исходным кодом, часть проекта `aio-libs`. Она представляет собой полнофункциональный веб-клиент и веб-сервер, т. е. умеет отправлять веб-запросы и может стать основой для разработки асинхронных веб-серверов.

#### 10.4.2.2 Асинхронные контекстные менеджеры

В любом языке программирования приходится работать с ресурсами, которые нужно открывать, а затем закрывать, например с файлами. При этом нужно помнить об исключениях – если исключение возникает, когда ресурс открыт, то может не представиться возможности для очистки, и в результате мы будем иметь утечку ресурсов. В Python эта проблема решается просто, с использованием блока `with`:

```Python
with open('example.txt') as file:
	lines = file.readlines()
```

Если внутри блока `with` возникнет исключение, файл автоматически будет закрыт. Это работает для синхронных ресурсов, но что делать, если мы хотим применить этот механизм асинхронно? В таком случае контекстный менеджер не подходит, потому что предназначен только для работы с синхронным Python-кодом, а не с сопрограммами и задачами. По этой причине в язык было включено новое сред-
ство: асинхронные контекстные менеджеры. Синтаксис почти такой же, только вместо `with` нужно писать `async with`.

**Асинхронный контекстный менеджер – это класс, реализующий два специальных метода-сопрограммы**: `__aenter__`, который асинхронно захватывает ресурс, и `__aexit__`, который закрывает ресурс. Сопрограмма `__aexit__` принимает несколько аргументов, относящихся к обработке исключений.

```Python
class AsyncConnection:
	def __init__(self):
		# Конструктор менеджера
		pass

	async def __aenter__(self):
		# Этот метод вызывается при входе в блок with
		pass

	async def __aexit__(self):
		# Этот метод вызывается при выходе из блока with. В ней производится очистка ресурса
		pass
```

В `aiohttp` асинхронные контекстные менеджеры вовсю используются для создания HTTP-сеансов и подключений.
#### 10.4.2.2 Отправка веб-запроса с помощью `aiohttp`

Установка библиотеки

```Shell
pip install aiohttp
```

В библиотеке `aiohttp` и вообще при работе с веб-запросами используется понятие сеанса. Сеанс можно рассматривать как создание нового окна браузера. В этом окне можно открывать разные веб-страницы, которые могут посылать куки, сохраняемые браузером. Внутри сеанса хранится много открытых подключений, их можно при
необходимости использовать повторно. Это называется **пулом подключений** и играет важную роль в производительности приложений на базе `aiohttp`. Поскольку создание подключения – дорогостоящее действие, наличие пула повторно используемых подключений сокращает затраты на выделение и освобождение ресурсов. Сеанс также самостоятельно сохраняет все полученные куки.

Как правило, мы хотим пользоваться преимуществами пула подключений, поэтому в большинстве приложений на базе `aiohttp` создается один сеанс для всего приложения. Затем объект сеанса передается методам. У объекта сеанса имеются методы для отправки веб-запросов, в том числе GET, PUT и POST. Для создания сеанса используется синтаксис `async with` и асинхронный контекстный менеджер `aiohttp.ClientSession`.

```Python
import asyncio
import aiohttp

from aiohttp import ClientSession


proxy_address = 'http://10.92.239.85:3128'


async def fetch_status(session: ClientSession, url: str) -> int:
    async with session.get(url, proxy=proxy_address) as result:
        return result.status


async def main():
    async with aiohttp.ClientSession() as session:
        url = 'https://mail.ru'
        status = await fetch_status(session, url)
        print(f'Состояние для {url} было равно {status}')


asyncio.run(main())
```

**Задание тайм-аутов в `aiohttp`**

По умолчанию тайм-аут равен 5 мин., т. е. никакая операция не будет выполняться дольше. Это большой тайм-аут, и многие разработчики предпочитают его уменьшить. Тайм-аут можно задавать на уровне сеанса, тогда он будет применяться к каждой операции, или на уровне запроса, если требуется более точное управление.

Тайм-аут задается с помощью структуры данных `aiohttp.ClientTimeout`. Она позволяет установить не только общий тайм-аут в секундах для всего запроса, но также отдельные тайм-ауты для установления соединения или чтения данных. Рассмотрим, как задать тайм-аут для сеанса и для одного запроса.

```Python
import asyncio
import aiohttp

from aiohttp import ClientSession

proxy_address = 'http://10.92.239.85:3128'


async def fetch_status(session: ClientSession, url: str) -> int:
    ten_milis = aiohttp.ClientTimeout(total=.01)
    async with session.get(url, proxy=proxy_address, timeout=ten_milis) as result:
        return result.status


async def main():
    session_timeout = aiohttp.ClientTimeout(total=1, connect=.1)
    async with aiohttp.ClientSession(timeout=session_timeout) as session:
        await fetch_status(session, 'https://mail.ru')


# изменение политики цикла событий для Windows
asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())

asyncio.run(main())
```

Здесь задается два тайм-аута. Первый – на уровне клиентского сеанса, полный тайм-аут равен 1 с, а тайм-аут для установления соединения – 100 мс. Затем в функции `fetch_status` мы переопределяем этот тайм-аут для нашего GET-запроса, задавая его равным 10 мс. Если запрос к `url` займет более 10 мс, то будет возбуждено
исключение `asyncio.TimeoutError` в точке `await fetch_status`.

#### 10.4.2.3 [[7. Многопоточность и многозадачность#7.2.6 Конкурентное выполнение запросов с помощью `gather`]]




















### 10.4.3 Django

#TODO 

### 10.5 API

### 10.5.1 REST/SOAP/gRPC

**REST** (от англ. Representational State Transfer - “передача репрезентативного состояния” или “передача “самоописываемого”состояния”) - архитектурный стиль взаимодействия компонентов распределенного приложения в сети. Другими словами, REST - это **набор правил того, как программисту организовать написание кода серверного приложения, чтобы все системы легко обменивались данными и приложение можно было масштабировать**. REST представляет собой согласованный набор ограничений, учитываемых при проектировании распределенной гипермедиа-системы. В определенных случаях (интернет-магазины, поисковые системы, прочие системы, основанные на данных) это приводит к повышению производительности и упрощению архитектуры. В широком смысле компоненты в REST взаимодействуют наподобие взаимодействия клиентов и серверов во Всемирной паутине. REST является альтернативой RPC.

В сети Интернет вызов удаленной процедуры может представлять собой обычный HTTP-запрос (обычно GET или POST; такой запрос называют «REST-запрос»), а необходимые данные передаются в качестве параметров запроса. Для веб-служб, построенных с учетом REST (то есть не нарушающих накладываемых им ограничений), применяют термин «RESTful».

В отличие от веб-сервисов (веб-служб) на основе SOAP, не существует «официального» стандарта для RESTful веб-API. Дело в том, что REST является архитектурным стилем, в то время как SOAP является протоколом. Несмотря на то, что REST не является стандартом сам по себе, большинство RESTful-реализаций используют такие стандарты, как HTTP, URL, [JSON](https://habr.com/ru/post/554274/) и, реже, XML.

**Требования к архитектуре REST**

Существует шесть обязательных ограничений для построения распределенных REST-приложений по Филдингу.

Выполнение этих ограничений обязательно для REST-систем. Накладываемые ограничения определяют работу сервера в том, как он может обрабатывать и отвечать на запросы клиентов. Действуя в рамках этих ограничений, система приобретает такие желательные свойства как производительность, масштабируемость, простота, способность к изменениям, переносимость, отслеживаемость и надёжность. Если сервис-приложение нарушает любое из этих ограничительных условий, данную систему нельзя считать REST-системой.

Обязательными условиями-ограничениями являются:
- **Модель клиент-сервер**: Первым ограничением, применимым к гибридной модели, является приведение архитектуры к модели клиент-сервер. Разграничение потребностей является принципом, лежащим в основе данного накладываемого ограничения. Отделение потребности интерфейса клиента от потребностей сервера, хранящего данные, повышает переносимость кода клиентского интерфейса на другие платформы, а упрощение серверной части улучшает масштабируемость. Наибольшее же влияние на всемирную паутину, пожалуй, имеет само разграничение, которое позволяет отдельным частям развиваться независимо друг от друга, поддерживая потребности в развитии интернета со стороны различных организаций.
- **Отсутствие состояния**: Протокол взаимодействия между клиентом и сервером требует соблюдения следующего условия: в период между запросами клиента никакая информация о состоянии клиента на сервере не хранится (Stateless protocol или «протокол без сохранения состояния»). Все запросы от клиента должны быть составлены так, чтобы сервер получил всю необходимую информацию для выполнения запроса. Состояние сессии при этом сохраняется на стороне клиента. Информация о состоянии сессии может быть передана сервером какому-либо другому сервису (например, в службу базы данных) для поддержания устойчивого состояния, например, на период установления аутентификации. Клиент инициирует отправку запросов, когда он готов (возникает необходимость) перейти в новое состояние. Во время обработки клиентских запросов считается, что клиент находится в переходном состоянии. Каждое отдельное состояние приложения представлено связями, которые могут быть задействованы при следующем обращении клиента.
- **Кэширование**: Информация должна быть проверяема, иначе она может быть удалена. Вы можете отредактировать статью, добавив ссылки на авторитетные источники. Эта отметка установлена 16 марта 2017 года. Как и во Всемирной паутине, клиенты, а также промежуточные узлы, могут выполнять кэширование ответов сервера. Ответы сервера, в свою очередь, должны иметь явное или неявное обозначение как кэшируемые или некэшируемые с целью предотвращения получения клиентами устаревших или неверных данных в ответ на последующие запросы. Правильное использование кэширования способно частично или полностью устранить некоторые клиент-серверные взаимодействия, еще больше повышая производительность и масштабируемость системы.
- **Единообразие интерфейса**: Наличие унифицированного интерфейса является фундаментальным требованием дизайна REST-сервисов. Унифицированные интерфейсы позволяют каждому из сервисов развиваться независимо. К унифицированным интерфейсам предъявляются следующие четыре ограничительных условия:
    - Идентификация ресурсов: Все ресурсы идентифицируются в запросах, например, с использованием URI в интернет-системах. Ресурсы концептуально отделены от представлений, которые возвращаются клиентам. Например, сервер может отсылать данные из базы данных в виде HTML, XML или JSON, ни один из которых не является типом хранения внутри сервера.
    - Манипуляция ресурсами через представление: Если клиент хранит представление ресурса, включая метаданные - он обладает достаточной информацией для модификации или удаления ресурса.
    - «Самоописываемые» сообщения: Каждое сообщение содержит достаточно информации, чтобы понять, каким образом его обрабатывать. К примеру, обработчик сообщения (parser), необходимый для извлечения данных, может быть указан в списке MIME-типов.
    - Гипермедиа как средство изменения состояния приложения (HATEOAS): Клиенты изменяют состояние системы только через действия, которые динамически определены в гипермедиа на сервере (к примеру, гиперссылки в гипертексте). Исключая простые точки входа в приложение, клиент не может предположить, что доступна какая-то операция над каким-то ресурсом, если не получил информацию об этом в предыдущих запросах к серверу. Не существует универсального формата для предоставления ссылок между ресурсами, Web Linking (RFC 5988 -> RFC 8288) и JSON Hypermedia API Language являются двумя популярными форматами предоставления ссылок в REST HYPERMEDIA сервисах.
- **Слои**: Клиент обычно не способен точно определить, взаимодействует он напрямую с сервером или же с промежуточным узлом, в связи с иерархической структурой сетей (подразумевая, что такая структура образует слои). Применение промежуточных серверов способно повысить масштабируемость за счет балансировки нагрузки и распределенного кэширования. Промежуточные узлы также могут подчиняться политике безопасности с целью обеспечения конфиденциальности информации.
- **Код по требованию** (необязательное ограничение): Информация должна быть проверяема, иначе она может быть удалена. Вы можете отредактировать статью, добавив ссылки на авторитетные источники. Эта отметка установлена 16 марта 2017 года. REST может позволить расширить функциональность клиента за счёт загрузки кода с сервера в виде апплетов или скриптов. Филдинг утверждает, что дополнительное ограничение позволяет проектировать архитектуру, поддерживающую желаемую функциональность в общем случае, но, возможно, за исключением некоторых контекстов.

Просто посмотреть как выглядят запросы-ответы можно во вкладке Network в DevTools. Попробовать отправить запрос и посмотреть ответ можно с помощью [этой статьи](https://www.software-testing.ru/library/testing/testing-automation/2958-testing-get-requests).

**SOAP**

SOAP (от англ. Simple Object Access Protocol - простой протокол доступа к объектам) - протокол обмена структурированными сообщениями в распределенной вычислительной среде. Первоначально SOAP предназначался в основном для реализации удаленного вызова процедур (RPC). Сейчас протокол используется для обмена произвольными сообщениями в формате [**XML**](https://habr.com/ru/post/524288/), а не только для вызова процедур. Официальная спецификация последней версии 1.2 протокола никак не расшифровывает название SOAP.

SOAP является расширением протокола XML-RPC. SOAP может использоваться с любым протоколом прикладного уровня: SMTP, FTP, HTTP, HTTPS и др. Однако его взаимодействие с каждым из этих протоколов имеет свои особенности, которые должны быть определены отдельно. Чаще всего SOAP используется поверх HTTP. SOAP является одним из стандартов, на которых базируются технологии веб-служб.

​[Структура](https://www.w3schools.com/xml/xml_soap.asp) протокола:

- Envelope - корневой элемент, который определяет сообщение и пространство имен, использованное в документе;
- Header - содержит атрибуты сообщения, например: информация о безопасности или о сетевой маршрутизации;
- Body - содержит сообщение, которым обмениваются приложения;
- Fault - необязательный элемент, который предоставляет информацию об ошибках, которые произошли при обработке сообщений.

​[Пример SOAP-запроса на сервер интернет-магазина](https://ru.wikipedia.org/wiki/SOAP)​

​[**WSDL**](https://www.w3.org/TR/wsdl.html) - это описательный язык, основанный на языке разметки XML, и именно в wsdl описан веб-сервис, который вам придется тестировать. WSDL включает в себя информацию о местоположении сервиса, часто включает в себя XSD. Именно из WSDL SOAPUI генерирует проверяемые классы.

​[**XSD**](https://en.wikipedia.org/wiki/XML_Schema_(W3C)) - это язык описания структуры XML документа. Его также называют XML Schema. При использовании XML Schema XML парсер может проверить не только правильность синтаксиса XML документа, но также его структуру, модель содержания и типы данных.

Если Вы направите в веб-сервис нестандартный запрос, он ответит на это ошибкой. WSDL - это свод правил общения с вашим сервисом, соблюдая которые вы сможете с этим сервисом коммуницировать. Собственно WSDL и XSD подробно описывают что и в каком виде слать на сервер, чтобы получить хороший ответ.

Что тестируется в SOAP? Бизнес-логика и то, что схема валидируется сервером (а также, что она принимает на вход параметры правильного формата). Собственно все, что касается схемы, проверяется на этапе разработки, а после, только бизнес-логика (до того момента, пока опять не начнутся изменения в схеме).

**Отличия REST и SOAP**

SOAP и REST нельзя сравнивать напрямую, поскольку первый - это протокол (или, по крайней мере, пытается им быть), а второй - архитектурный стиль.

Основное различие между SOAP и REST заключается в степени связи между реализациями клиента и сервера. Клиент SOAP работает как пользовательское настольное приложение, тесно связанное с сервером. Между клиентом и сервером существует жесткое соглашение, и ожидается, что все сломается, если какая-либо из сторон что-то изменит. Вам нужно постоянное обновление после любого изменения, но легче определить, выполняется ли контракт.

SOAP более применим в сложных архитектурах, где взаимодействие с объектами выходит за рамки теории CRUD, а вот в тех приложениях, которые не покидают рамки данной теории, вполне применимым может оказаться именно REST ввиду своей простоты и прозрачности. Действительно, если любым объектам вашего сервиса не нужны более сложные взаимоотношения, кроме: «Создать», «Прочитать», «Изменить», «Удалить» (как правило - в 99% случаев этого достаточно), возможно, именно REST станет правильным выбором. Кроме того, REST по сравнению с SOAP, может оказаться и более производительным, так как не требует затрат на разбор сложных XML команд на сервере (выполняются обычные HTTP запросы - PUT, GET, POST, DELETE). Хотя SOAP, в свою очередь, более надежен и безопасен.

**gRPC**

Для тех, кто еще не слышал о gRPC, gRPC - это не зависящий от языка фреймворк для удаленного вызова процедур (RPC, remote procedure calls), разработанный Google, которая серьезно вкладывается в производительность и масштабирование. Он появился довольно давно, но многие отложили его на второй план из-за затрат на написание IDL и дополнительного кода стабов (stub), который тоже необходимо поддерживать. В то же время REST очень легко реализуется с помощью ASP.NET Core WebAPI.

Аналогично использованию JSON для REST, для gRPC используется [Protocol Buffers](https://developers.google.com/protocol-buffers) - не зависящий от языка формат для сериализации структурированных данных. Этим gRPC отличается от REST. Поддержка Protocol Buffers есть для всех основных языков благодаря компилятору protoc, который генерирует необходимый исходный код классов из определений в proto-файле. Еще важный момент состоит в том, что для связи gRPC использует HTTP/2, а это приносит дополнительные преимущества, такие как сжатие HTTP-заголовков и мультиплексирование запросов.

### 10.5.2 Postman

**Postman** — приложение для работы с API. Это популярный API клиент, который позволяет разрабатывать, тестировать и документировать API. Мы можем отсылать HTTP/s запросы к сервисам и получать от них ответы. С помощью такого подхода можно протестировать бэкенд сервисы и убедиться, что они корректно работают.

**Интерфейс**

![[Pasted image 20230712153640.png]]

1. **New:** С помощью этой кнопки можно создать новый запрос (Request), коллекцию (Collection) или окружение (Environment).
2. **Import:** С помощью этой кнопки можно импортировать коллекцию или окружение. По нажатию откроется окно, где вы сможете выбрать одну из нескольких опций для импорта: импорт из файла, папки или по ссылке. Также можно просто вставить данные для импорта в текстовое поле.
3. **Runner:** По нажатию на кнопку запускается Collection Runner, который выполняет коллекции запросов.
4. **Open New:** По нажатию открывается новое окно Postman или новое окно запуска коллекций.
5. **My Workspace:** Моя рабочая область. С помощью этой кнопки можно создать новую рабочую область (workspace). Рабочая область предоставляет общий контекст для работы с API. Может использоваться для совместной работы внутри команды (ее можно расшарить с коллегами).
6. **Invite:** С помощью этой кнопки можно пригласить других членов команды для совместной работы внутри рабочей области (workspace-а)
7. **History:** Все запросы и ответы попадают во вкладку «History» (История). Это позволяет вернуться к предыдущим запросам.
8. **Collections:** В этой вкладке хранятся коллекции запросов. Коллекции используются для группировки запросов по каким-либо признакам.
9. **Request Tab:** Вкладка запроса. Название вкладки по умолчанию — Untitled Project. Хорошая практика — называть вкладку по названию запроса.
10. **HTTP Request:** С помощью этого выпадающего списка можно выбрать тип запроса: GET, POST, PUT, PATCH, DELETE и т.п.
11. **Request URL:** URL API запроса.
12. **Save:** По нажатию на кнопку Save можно сохранить запрос (или перезаписать, если запрос уже был сохранен ранее)
13. **Params:** Параметры, необходимые для выполнения запроса.
14. **Authorization:** API используют авторизацию, чтобы убедиться, что клиент имеет доступ к запрашиваемым данным. В этой секции описываются параметры авторизации: например, username, password, bearer-токен и т.п.
15. **Headers:** Для работы с некоторыми API с каждым запросом необходимо отправлять специальные хедеры. Это нужно для того, чтобы добавить дополнительные данные о типе операции, которую вы хотите провести. Хедеры можно указать в этой секции.
16. **Body:** В этой вкладке указываются данные, которые должны быть отправлены вместе с запросом.
17. **Pre-request Script:** Pre-request скрипты пишутся на JavaScript и выполняются перед отправкой запросов. Используются для того, чтобы провести какие-то действия прямо перед тем, как отправить запрос (например, добавить timestamp или какие-то вычисляемые данные в ваши запросы)
18. **Tests:** Во вкладке Tests находятся скрипты, которые выполняются во время запроса. Тесты позволяют проверить API и убедиться, что все работает так, как это было задумано.

**Основные сущности Postman: запросы, коллекции и окружения**

**Запросы (Requests)**

Запрос представляет собой комбинацию URL, хедеров и Body (тела запроса). Postman позволяет сохранять запросы и использовать их в будущем там, где вам нужно.

Чтобы создать новый запрос, нажмите **New — Request**

![[Pasted image 20230712153822.png]]
![[Pasted image 20230712153853.png]]

**Коллекции (Collections)**

Коллекции представляют собой группы запросов. Вы можете думать о коллекциях как о папках, в которых лежат запросы.

**Как создать коллекцию в Postman:**

Нажмите **New — Collection**

Введите имя (Name) и описание (Description) коллекции, после этого нажмите кнопку Create:

![[Pasted image 20230712153947.png]]

Коллекция может содержать любое число запросов. Запустить выполнение коллекции можно двумя способами:

1. с помощью Collection Runner
2. c помощью Newman

**Окружение (Environments)**

Окружения в Postman позволяют запускать запросы и коллекции, используя разные наборы данных. Например, мы можем создавать разные окружения в Postman для Dev, QA и Production серверов. В каждом из окружений будут свои собственные настройки: например, URL, auth token-ы и пароли, API-ключи и т.п. Окружения представляют собой наборы пар «ключ-значение».

Чтобы создать новое окружение (Environment), нажмите **New — Environment**

![[Pasted image 20230712154037.png]]

**Тестирование GET-запросов**

Для обучения мы будем использовать простой открытый API: [http://dummy.restapiexample.com/api/v1/employees](http://dummy.restapiexample.com/api/v1/employees)

Давайте отправим GET-запрос с помощью Postman:

**Шаг 1:** Открываем новую вкладку, чтобы создать запрос (нажимаем на «+»):

![[Pasted image 20230712154132.png]]

**Шаг 2:** Создаем GET-запрос:

1. Задаем тип запроса — **GET**
2. Задаем request URL — https://jsonplaceholder.typicode.com/users
3. Нажимаем на кнопку SEND, чтобы выполнить запрос.
4. Вы увидите 200 OK в результате, если запрос выполнится успешно. Бывают случаи, когда GET-запросы выполняются с ошибками (например, при неправильном URL, некорректными авторизационными данными или из-за ошибок на стороне сервера)

После выполнения запроса вы должны будете увидеть данные от сервера во вкладке Body.

На скриншоте ниже вы видите код ответа сервера (Status: 200 OK), время выполнения запроса (Time: 1700ms) и размер ответа (Size: 1.62 KB)

## Тестирование POST-запросов

POST-запросы используются для **отправки новых данных** на сервер. Давайте попробуем с помощью POST-запроса добавить нового пользователя. Для этого мы отправим информацию о новом пользователе в теле POST-запроса.

1. Задаем тип запроса — **POST**
2. Задаем request URL — https://jsonplaceholder.typicode.com/users
3. Нажимаем на вкладку Body, выбираем «Raw» — JSON. Вставляем данные о пользователе из сниппета ниже:

```JSON
{
	"id": 11,
	"name": "Rajkumar SM",
	"username": "stm",
	"email": "user@testengineer.ru",
	"address": {
			"street": "Gagarina",
			"suite": "31",
			"city": "Moscow",
			"zipcode": "600007",
			"geo": {
			"lat": "10.0000",
			"lng": "80.0000"
	}
}
```

После этого наживаем кнопку **SEND** и отправляем POST-запрос.

![[Pasted image 20230712154433.png]]

1. Вы увидите 201 Created message (как на скриншоте ниже), если запрос выполнился успешно.
2. Данные, отправленные с помощью POST-запроса будут показаны во вкладке Body

![[Pasted image 20230712154452.png]]

Точно так же, как и POST, отправляются PUT, PATCH и DELETE запросы.

**Примечание:** во время тестирования, для каждого запроса проверяйте возвращаемый результат, код ответа сервера и время ответа сервера. И не забывайте про негативные тесты!

**Параметризация запросов**

Параметризация — одна из самых полезных особенностей Postman.

Часто необходимо выполнить один и тот же запрос на разных наборах данных. С помощью параметризации, можно использовать переменные при выполнении запросов.

В Postman, параметры создаются с помощью двойных скобок: **{{test}}**.

Например, наш base URL — **https://testengineer.ru** и мы сохраняем это значение в переменной с именем **base_url**. В этом случае, мы можем обратиться к этой переменной из запроса, написав **_{{base_url}}_**. Для того, чтобы отправить запрос на этот URL, мы подставим эту переменную в запрос. Выглядеть это будет так: **_{{base_url}}/get?customers=new_**. Запрос будет отправлен на **https://testengineer.ru/get?customers=new**

**Шаг 1:** Меняем тип HTTP-запроса на GET и вводим URL:

![[Pasted image 20230712154543.png]]

**Шаг 2:** Меняем URL на параметр {{url}}. После этого URL запроса должен быть таким: **_{{url}}/users_**

![[Pasted image 20230712154602.png]]

**Шаг 3:** Теперь нам нужно создать переменную окружения, чтобы использовать ее в качестве параметра. Для этого нажимаем на кнопку с глазом и кликаем на Edit (редактировать), чтобы создать глобальную переменную и затем использовать ее в коллекциях.

![[Pasted image 20230712154614.png]]

**Шаг 4:** В окне создания переменной задаем имя (именем будет url) и значение (значением будет https://jsonplaceholder.typicode.com). После этого нажимаем Save (Сохранить)

![[Pasted image 20230712154633.png]]

**Шаг 5:** Возвращаемся к GET-запросу и нажимаем Send (отправить)

![[Pasted image 20230712154655.png]]

Если все сделано правильно, значение переменной, которую мы создали, будет подставлено вместо ее имени и запрос выполнится успешно.

**Создание тестов в Postman**

Тесты в Postman позволяют убедиться, что API работает так, как этого от него ожидают.

Давайте начнем с написания простого теста.

**Шаг 1:** Возвращаемся к GET-запросу, который мы создали ранее и переключаемся во вкладку Tests (Тесты). В секции сниппетов нажимаем на сниппет «Status code: Code is 200». В окне теста появится скрипт. Этот скрипт будет проверять, что запрос возвращает код ответа 200.

![[Pasted image 20230712154733.png]]

**Шаг 2:** Нажмите кнопку Send (Отправить). В нижней части окна вы увидите результат выполнения теста (в нашем случае он выполнился успешно).

![[Pasted image 20230712154755.png]]

**Шаг 3:** Давайте добавим еще один тест. В этот тесте мы будем сравнивать полученный результат с ожидаемым. Чтобы это сделать, выбираем сниппет с названием «Response body:JSON value check». Давайте проверим, что пользователь с именем Leanne Graham имеет userid 1.

![[Pasted image 20230712154806.png]]

**Шаг 4:** Заменим название теста на что-то более понятное: вместо «Your test name» напишем «Check if Leanne Graham has the userid 1». Также заменим `jsonData.value` на `jsonData[0].name` (т.к. jsonData представляет собой массив, а массивы начинаются с 0):

![[Pasted image 20230712154820.png]]

Код теста будет выглядеть следующим образом:

```
pm.test("Check if user with id1 is Leanne Graham", function () {
	var jsonData = pm.response.json();
	pm.expect(jsonData[0].name).to.eql("Leanne Graham");
});
```

**Шаг 5:** Нажимаем Send (Отправить)

![[Pasted image 20230712154911.png]]

**Запуск коллекций с помощью Collection Runner**

Давайте запустим коллекцию с помощью Collection Runner.

**Шаг 1:** Нажимаем на кнопку «Runner» (находится рядом с кнопкой Import)

![[Pasted image 20230712154938.png]]

**Шаг 2:** Должна будет открыться следующая страница:

![[Pasted image 20230712154958.png]]

Разберем основные элементы:

2 — Resent Runs: Все предыдущие запуски

3 — Environment: Окружение. Если вы хотите запустить коллекцию в конкретном окружении, вы можете выбрать его в этом поле.

4 — Iterations: Количество итераций

5 — Delay: Задержка. Указывается в миллисекундах. Выполнение тестов без задержки может вызвать ошибки, поэтому всегда указывайте небольшую задержку.

7 — Start Run: Кнопка для запуска коллекции

**Шаг 3:** В этом окне добавим коллекцию для запуска. Выбираем нашу коллекцию тестов, устанавливаем параметр Iterations в 2, delay в 2500ms и нажимаем кнопку запуска.

![[Pasted image 20230712155019.png]]

**Шаг 4:** После выполнения откроется отчет. В нашей коллекции были GET и POST запросы, но тесты мы добавляли только для GET-запроса. Поэтому в отчете рядом с POST-запросом показывается текст «This request doesn’t have any tests.» (для этого запроса нет тестов)

![[Pasted image 20230712155039.png]]

### 10.5.3 Аутентификация и авторизация (Authentication and authorization)

**Идентификация** - процедура, в результате выполнения которой для субъекта идентификации выявляется его идентификатор, однозначно определяющий этого субъекта в информационной системе.

**Аутентификация** - процедура проверки подлинности, например проверка подлинности пользователя путем сравнения введенного им пароля с паролем, сохраненным в базе данных.

**Авторизация** - предоставление определенному лицу или группе лиц прав на выполнение определенных действий.

_В англоязычных источниках идентификация не выделяется в отдельный пункт: “Authentication is the process of_ **_identifying_** _users and_ **_validating_** _who they claim to be”._

Скажем, пользователь хочет войти в свой аккаунт Google. Вот что при этом происходит:
- Для начала система запрашивает логин, пользователь его указывает, система распознает его как существующий - это идентификация.
- После этого Google просит ввести пароль, пользователь его вводит, и система соглашается, что пользователь, похоже, действительно настоящий, раз пароль совпал, - это аутентификация.
- Скорее всего, Google дополнительно спросит еще и одноразовый код из SMS или приложения. Если пользователь и его правильно введет, то система окончательно согласится с тем, что он настоящий владелец аккаунта, - это двухфакторная аутентификация.
- После этого система предоставит пользователю право читать письма в его почтовом ящике и все в таком духе - это авторизация.

Аутентификация без предварительной идентификации лишена смысла - пока система не поймет, подлинность чего же надо проверять, совершенно бессмысленно начинать проверку. Для начала надо представиться.

Идентификация без аутентификации - это просто глупо. Потому что мало ли кто ввел существующий в системе логин! Системе обязательно надо удостовериться, что этот кто-то знает еще и пароль. Но пароль могли подсмотреть или подобрать, поэтому лучше подстраховаться и спросить что-то дополнительное, что может быть известно только данному пользователю: например, одноразовый код для подтверждения входа.

А вот авторизация без идентификации и тем более аутентификации очень даже возможна. Например, в Google Документах можно публиковать документы так, чтобы они были доступны вообще кому угодно. В этом случае вы как владелец файла увидите сверху надпись, гласящую, что его читает неопознанный енот. Несмотря на то, что енот совершенно неопознанный, система его все же авторизовала - то есть выдала право прочитать этот документ.

А вот если бы вы открыли этот документ для чтения только определенным пользователям, то еноту в таком случае сперва пришлось бы идентифицироваться (ввести свой логин), потом аутентифицироваться (ввести пароль и одноразовый код) и только потом получить право на чтение документа - авторизоваться.

**Фреймворк HTTP-аутентификации** (HTTP authentication framework)

​[RFC 7235](https://datatracker.ietf.org/doc/html/rfc7235) определяет HTTP authentication framework, который может использоваться сервером для вызова клиентского запроса (to [challenge](https://developer.mozilla.org/en-US/docs/Glossary/challenge) a client request) и клиентом для предоставления информации для проверки подлинности. Порядок вызовов и ответов:
- Сервер отвечает клиенту со статусом ответа 401 (Unauthorized) и предоставляет информацию о том, как авторизоваться, с WWW-Authenticate response header, содержащим как минимум один вызов.
- Клиент, который хочет аутентифицировать себя на сервере, может сделать это, включив Authorization request header с учетными данными (credentials).
- Обычно клиент представляет пользователю запрос пароля, а затем отправляет запрос, включая правильный Authorization header.

![[Pasted image 20230712150906.png]]

**Популярные методы аутентификации**

- Проверка подлинности на основе пароля (**Password-based authentication**) - это простой метод проверки подлинности, требующий ввода пароля для подтверждения личности пользователя.

- Беспарольная аутентификация (**Passwordless authentication**) - это когда пользователь проверяется с помощью одноразового ПИН-а (OTP - One-time pins) или magic link, доставленной на зарегистрированный адрес электронной почты или номер телефона;

- Для двухфакторной аутентификации/многофакторной аутентификации (**2FA/MFA**) требуется более одного уровня безопасности, например дополнительный PIN-код или контрольный вопрос, для идентификации пользователя и предоставления доступа к системе;

- Единый вход (**SSO**) позволяет пользователям получать доступ к нескольким приложениям с одним набором учетных данных;

- Социальная аутентификация (**Social authentication**) проверяет и аутентифицирует пользователей с существующими учетными данными на платформах социальных сетей.

- Биометрия ([**Biometrics**](https://hackernoon.com/biometric-authentication-working-methods-and-use-cases-3z2a377p)) - пользователь предъявляет отпечаток пальца или скан глаза, чтобы получить доступ к системе.

**Популярные методы авторизации**

- Управление доступом на основе ролей (**RBAC - Role-based access controls**) может быть реализовано для управления привилегиями от системы к системе и от пользователя к системе.

- Веб-токен JSON ([**JWT - JSON web token**](https://gist.github.com/zmts/802dc9c3510d79fd40f9dc38a12bccfc)) - это открытый стандарт для безопасной передачи данных между сторонами, а пользователи авторизуются с помощью пары открытый/закрытый ключ.

- **SAML** - это стандартный формат единого входа (SSO), в котором аутентификационная информация передается через XML-документы с цифровой подписью.

- Авторизация [**OpenID**](https://habr.com/ru/company/nixys/blog/566910/) проверяет личность пользователя на основе аутентификации сервера авторизации;

- [**OAuth**](https://betterprogramming.pub/the-complete-guide-to-oauth-2-0-and-openid-connect-protocols-35ebc1cbc11a) позволяет API аутентифицировать и получать доступ к запрошенной системе или ресурсу.

**Аутентификация на основе сессий**

Протокол HTTP не отслеживает состояния, и, если мы аутентифицируем пользователя с помощью имени и пароля, наше приложение не будет знать, тот ли это человек, что и в предыдущем запросе. Нам придётся аутентифицировать снова. При каждом запросе HTTP не знает ничего о том, что происходило до этого, он лишь передаёт запрос. Так что, если вам нужны личные данные, придётся снова логиниться, чтобы приложение знало, что это точно вы. Это может сильно раздражать.

Чтобы избавиться от этого неудобства, придумали аутентификацию на основе сессий/кук, с помощью которых реализовали отслеживание состояний (stateful). Это означает, что аутентификационная запись или сессия должны храниться и на сервере, и на клиенте. Сервер должен отслеживать активные сессии в базе данных или памяти, а на фронтенде создаётся кука, в которой хранится идентификатор сессии. Это аутентификация на основе куки, самая распространенный и широко известный метод, используемый уже давно.

Процедура аутентификации на основе сессий:
- Пользователь вводит в браузере своё имя и пароль, после чего клиентское приложение отправляет на сервер запрос.
- Сервер проверяет пользователя, аутентифицирует его, шлёт приложению уникальный пользовательский токен (сохранив его в памяти или базе данных).
- Клиентское приложение сохраняет токены в куках и отправляет их при каждом последующем запросе.
- Сервер получает каждый запрос, требующий аутентификации, с помощью токена аутентифицирует пользователя и возвращает запрошенные данные клиентскому приложению.
- Когда пользователь выходит, клиентское приложение удаляет его токен, поэтому все последующие запросы от этого клиента становятся неаутентифицированными.
![[Pasted image 20230712151227.png]]
У этого метода несколько недостатков:

- При каждой аутентификации пользователя сервер должен создавать у себя запись. Обычно она хранится в памяти, и при большом количестве пользователей есть вероятность слишком высокой нагрузки на сервер.

- Поскольку сессии хранятся в памяти, масштабировать не так просто. Если вы многократно реплицируете сервер, то на все новые серверы придётся реплицировать и все пользовательские сессии. Это усложняет масштабирование. (Я считал, этого можно избежать, если иметь выделенный сервер для управления сессиями, но это сложно реализовать, да и не всегда возможно.)

**Беспарольная аутентификация**

Первой реакцией на термин «беспарольная аутентификация» может быть «Как аутентифицировать кого-то без пароля? Разве такое возможно?». В наши головы внедрено убеждение, что пароли - абсолютный источник защиты наших аккаунтов. Но если изучить вопрос глубже, то выяснится, что беспарольная аутентификация может быть не просто безопасной, но и безопаснее традиционного входа по имени и паролю. Возможно, вы даже слышали мнение, что пароли устарели.

Беспарольная аутентификация - это способ конфигурирования процедуры входа и аутентификации пользователей без ввода паролей. Идея такая: вместо ввода почты/имени и пароля пользователи вводят только свою почту. Ваше приложение отправляет на этот адрес одноразовую ссылку, пользователь по ней кликает и автоматически входит на ваш сайт / в приложение. При беспарольной аутентификации приложение считает, что в ваш ящик пришло письмо со ссылкой, если вы написали свой, а не чужой адрес.

Есть похожий метод, при котором вместо одноразовой ссылки по SMS отправляется код или одноразовый пароль. Код или одноразовый пароль тоже можно отправлять по почте.

И ещё один, менее (пока) популярный (и доступный только на устройствах Apple) метод беспарольной аутентификации: использовать Touch ID для аутентификации по отпечаткам пальцев.

Что может пойти не так: если кто-то получит доступ к пользовательским почтам, он получит и доступ к приложениям и сайтам. Но это не ваша головная боль - беспокоиться о безопасности почтовых аккаунтов пользователей. Кроме того, если кто-то получит доступ к чужой почте, то сможет перехватить аккаунты в приложениях с беспарольной аутентификацией, воспользовавшись функцией восстановления пароля. Но мы ничего не можем поделать с почтой наших пользователей. Пойдём дальше.

В чём преимущества: как часто вы пользуетесь ссылкой «забыли пароль» для сброса чертового пароля, который так и не смогли вспомнить после нескольких неудачных попыток входа на сайт / в приложение? Все мы бываем в такой ситуации. Все пароли не упомнишь, особенно если вы заботитесь о безопасности и для каждого сайта делаете отдельный пароль (соблюдая все эти «должен состоять не менее чем из восьми символов, содержать хотя бы одну цифру, строчную букву и специальный символ»). От всего этого вас избавит беспарольная аутентификация. Знаю, вы думаете сейчас: «Я использую менеджер паролей, идиот». Уважаю. Но не забывайте, что подавляющее большинство пользователей не такие техногики, как вы. Это нужно учитывать.

**Единая точка входа (Single Sign On, SSO)**

Обращали внимание, что, когда логинишься в браузере в каком-нибудь Google-сервисе, например Gmail, а потом идёшь на Youtube или иной Google-сервис, там не приходится логиниться? Ты автоматически получаешь доступ ко всем сервисам компании. Впечатляет, верно? Ведь хотя Gmail и Youtube - это сервисы Google, но всё же раздельные продукты. Как они аутентифицируют пользователя во всех продуктах после единственного входа? Этот метод называется единой точкой входа (Single Sign On, SSO).

Реализовать его можно по-разному. Например, использовать центральный сервис для оркестрации единого входа между несколькими клиентами. В случае с Google этот сервис называется Google Accounts. Когда пользователь логинится, Google Accounts создает куку, которая сохраняется за пользователем, когда тот ходит по принадлежащим компании сервисам. Как это работает:
- Пользователь входит в один из сервисов Google.
- Пользователь получает сгенерированную в Google Accounts куку.
- Пользователь идёт в другой продукт Google.
- Пользователь снова перенаправляется в Google Accounts.
- Google Accounts видит, что пользователю уже присвоена кука, и перенаправляет пользователя в запрошенный продукт.

Очень простое описание единой точки входа: пользователь входит один раз и получает доступ ко всем системам без необходимости входить в каждую из них. В этой процедуре используется три сущности, доверяющие другу прямо и косвенно. Пользователь вводит пароль (или аутентифицируется иначе) у поставщика идентификационной информации (identity provider, IDP), чтобы получить доступ к поставщику услуги (service provider (SP). Пользователь доверяет IDP, и SP доверяет IDP, так что SP может доверять пользователю. Выглядит очень просто, но конкретные реализации бывают очень сложными. [Подробнее об этом методе аутентификации](https://auth0.com/blog/what-is-and-how-does-single-sign-on-work/).

**Аутентификация в соцсетях (Social sign-in)** или социальный логин (Social Login)

Вы можете аутентифицировать пользователей по их аккаунтам в соцсетях. Тогда пользователям не придётся регистрироваться отдельно в вашем приложении.

Формально социальный логин - это не отдельный метод аутентификации. Это разновидность единой точки входа с упрощением процесса регистрации/входа пользователя в ваше приложение.

Лучшее из двух миров: пользователи могут войти в ваше приложение одним кликом, если у них есть аккаунт в одной из соцсетей. Им не нужно помнить логины и пароли. Это сильно улучшает опыт использования вашего приложения. Вам не нужно волноваться о безопасности пользовательских данных и думать о проверке адресов почты - они уже проверены соцсетями. Кроме того, в соцсетях уже есть механизмы восстановления пароля.

Как использовать: большинство соцсетей в качестве механизма аутентификации используют авторизацию через OAuth2 (некоторые используют OAuth1, например Twitter). Разберёмся, что такое OAuth. Соцсеть - это сервер ресурсов, ваше приложение - клиент, а пытающийся войти в ваше приложение пользователь - владелец ресурса. Ресурсом называется пользовательский профиль / информация для аутентификации. Когда пользователь хочет войти в ваше приложение, оно перенаправляет пользователя в соцсеть для аутентификации (обычно это всплывающее окно с URL’ом соцсети). После успешной аутентификации пользователь должен дать вашему приложению разрешение на доступ к своему профилю из соцсети. Затем соцсеть возвращает пользователя обратно в ваше приложение, но уже с токеном доступа. В следующий раз приложение возьмёт этот токен и запросит у соцсети информацию из пользовательского профиля. Так работает OAuth (ради простоты я опустил технические подробности).

Для реализации такого механизма вам может понадобиться зарегистрировать свое приложение в разных соцсетях. Вам дадут app_id и другие ключи для конфигурирования подключения к соцсетям. Также есть несколько популярных библиотек/пакетов (вроде Passport, Laravel Socialite и т. д.), которые помогут упростить процедуру и избавят от излишней возни.

**Двухфакторная аутентификация (2FA)**

Двухфакторная аутентификация (2FA) улучшает безопасность доступа за счет использования двух методов (также называемых факторами) проверки личности пользователя. Это разновидность [многофакторной аутентификации](https://ru.wikipedia.org/wiki/%D0%9C%D0%BD%D0%BE%D0%B3%D0%BE%D1%84%D0%B0%D0%BA%D1%82%D0%BE%D1%80%D0%BD%D0%B0%D1%8F_%D0%B0%D1%83%D1%82%D0%B5%D0%BD%D1%82%D0%B8%D1%84%D0%B8%D0%BA%D0%B0%D1%86%D0%B8%D1%8F). Наверное, вам не приходило в голову, но в банкоматах вы проходите двухфакторную аутентификацию: на вашей банковской карте должна быть записана правильная информация, и в дополнение к этому вы вводите PIN. Если кто-то украдет вашу карту, то без кода он не сможет ею воспользоваться. (Не факт! - Примеч. пер.) То есть в системе двухфакторной аутентификации пользователь получает доступ только после того, как предоставит несколько отдельных частей информации.

Другой знакомый пример - двухфакторная аутентификация Mail.Ru, Google, Facebook и т. д. Если включён этот метод входа, то сначала вам нужно ввести логин и пароль, а затем одноразовый пароль (код проверки), отправляемый по SMS. Если ваш обычный пароль был скомпрометирован, аккаунт останется защищенным, потому что на втором шаге входа злоумышленник не сможет ввести нужный код проверки.

Вместо одноразового пароля в качестве второго фактора могут использоваться отпечатки пальцев или снимок сетчатки.

При двухфакторной аутентификации пользователь должен предоставить **два из трёх**:
- **То, что вы знаете**: пароль или PIN.
- **То, что у вас есть**: физическое устройство (смартфон) или приложение, генерирующее одноразовые пароли.
- **Часть вас**: биологически уникальное свойство вроде ваших отпечатков пальцев, голоса или снимка сетчатки.

Большинство хакеров охотятся за паролями и PIN-кодами. Гораздо труднее получить доступ к генератору токенов или биологическим свойствам, поэтому сегодня двухфакторка обеспечивает высокую безопасность аккаунтов.

И всё же двухфакторка поможет усилить безопасность аутентификации в вашем приложении. Как реализовать? Возможно, стоит не велосипедить, а воспользоваться существующими решениями вроде Auth0 или Duo.

### 10.5.4 Аутентификация на основе токенов (JWT Tokens)

Аутентификация на основе токенов в последние годы стала очень популярна из-за распространения одностраничных приложений, веб-API и интернета вещей. Чаще всего в качестве токенов используются **Json Web Tokens (JWT)**. Хотя реализации бывают разные, но токены **JWT** превратились в стандарт де-факто.

При аутентификации на основе токенов состояния не отслеживаются. Мы не будем хранить информацию о пользователе на сервере или в сессии и даже не будем хранить **JWT**, использованные для клиентов.

Процедура аутентификации на основе токенов:
- Пользователь вводит имя и пароль.
- Сервер проверяет их и возвращает токен (**JWT**), который может содержать метаданные вроде user_id, разрешений и т. д.
- Токен хранится на клиентской стороне, чаще всего в локальном хранилище, но может лежать и в хранилище сессий или кук.
- Последующие запросы к серверу обычно содержат этот токен в качестве дополнительного заголовка авторизации в виде `Bearer {JWT}`. Ещё токен может пересылаться в теле POST-запроса и даже как параметр запроса.
- Сервер расшифровывает **JWT**, если токен верный, сервер обрабатывает запрос.
- Когда пользователь выходит из системы, токен на клиентской стороне уничтожается, с сервером взаимодействовать не нужно.
![[Pasted image 20230712151521.png]]
У метода есть ряд преимуществ:

- Главное преимущество: поскольку метод никак не оперирует состояниями, серверу не нужно хранить записи с пользовательскими токенами или сессиями. Каждый токен самодостаточен, содержит все необходимые для проверки данные, а также передаёт затребованную пользовательскую информацию. Поэтому токены не усложняют масштабирование.

- В куках вы просто храните ID пользовательских сессий, а JWT позволяет хранить метаданные любого типа, если это корректный JSON.

- При использовании кук бэкенд должен выполнять поиск по традиционной SQL-базе или NoSQL-альтернативе, и обмен данными наверняка длится дольше, чем расшифровка токена. Кроме того, раз вы можете хранить внутри JWT дополнительные данные вроде пользовательских разрешений, то можете сэкономить и дополнительные обращения поисковые запросы на получение и обработку данных.

- Допустим, у вас есть API-ресурс /api/orders, который возвращает последние созданные приложением заказы, но просматривать их могут только пользователи категории админов. Если вы используете куки, то, сделав запрос, вы генерируете одно обращение к базе данных для проверки сессии, ещё одно обращение - для получения пользовательских данных и проверки, относится ли пользователь к админам, и третье обращение - для получения данных. А если вы применяете JWT, то можете хранить пользовательскую категорию уже в токене. Когда сервер запросит его и расшифрует, вы можете сделать одно обращение к базе данных, чтобы получить нужные заказы.

- У использования кук на мобильных платформах есть много ограничений и особенностей. А токены сильно проще реализовать на iOS и Android. К тому же токены проще реализовать для приложений и сервисов интернета вещей, в которых не предусмотрено хранение кук.

### 10.5.5 Swagger

#TODO 

### 10.5.6 FastAPI

Установка `FastApi` и его зависимостей

```
pip install fastapi uvicorn
```

создадим новый экземпляр `FastAPI`

```Python
from fastapi import FastAPI
app = FastAPI()
```

Создадим тестовый маршрут, сначала определяя декоратор для указания типа операции, а затем функцию, содержащую HTTP  операцию, которая будет выполняться при вызове этого маршрута. В следующем примере мы создадим маршрут "/", который принимает только запросы `GET` и возвращает приветственное сообщение при посещении:

```Python
@app.get("/")
async def welcome() -> dict:
	return { "message": "Hello World"}
```

Запускаем наше приложение с помощью `uvicorn`:

```Shell
uvicorn main:app --port 8000 --reload
```

В предыдущей команде, uvicorn принимает следующие аргументы:
Команда `uvicorn main:app` обращается к:
- `main`: файл `main.py` (модуль Python).
- `app`: объект, созданный внутри файла `main.py` в строке `app = FastAPI()`.
- `--reload`: перезапускает сервер после изменения кода. Используйте только для разработки.
- `--port PORT`: Порт, на котором будет обслуживаться приложение.

```Python
"""
FastAPI это класс в Python, который предоставляет всю функциональность для API.
"""
from fastapi import FastAPI

"""
Переменная app является экземпляром класса FastAPI.
Это единая точка входа для создания и взаимодействия с API.
Именно к этой переменной app обращается uvicorn
"""
app = FastAPI()

"""
определение операции пути (path operation), "Путь" это часть URL, после первого символа `/`, следующего за именем домена.

Декоратор @app.get("/") указывает FastAPI, что функция, прямо под ним, отвечает за обработку запросов, поступающих по адресу:
- путь `/`
- использующих `get` операцию
"""
@app.get("/")
async def root(): # определение функции операции пути FastAPI будет вызывать её каждый раз при получении GET запроса к URL "/".
    return {"message": "Hello World"}
```
#### OpenAPI

**FastAPI** генерирует "схему" всего API, используя стандарт **OpenAPI**.

[OpenAPI](https://github.com/OAI/OpenAPI-Specification) - это спецификация, которая определяет, как описывать схему API. Определение схемы содержит пути (paths) API, их параметры и т.п. Эта схема содержит определения (или "схемы") данных, отправляемых и получаемых API. Для описания структуры данных в JSON используется стандарт **JSON Schema**.
#### Path-параметры

Вы можете определить "параметры" или "переменные" пути, используя синтаксис форматированных строк Python

```Python
from fastapi import FastAPI

app = FastAPI()


@app.get("/items/{item_id}")
async def read_item(item_id):
    return {"item_id": item_id}
```

Значение параметра пути `item_id` будет передано в функцию в качестве аргумента `item_id`.

Если запустите этот пример и перейдёте по адресу: [http://127.0.0.1:8000/items/foo](http://127.0.0.1:8000/items/foo), то увидите ответ:

```Python
{"item_id":"foo"}
```

Вы можете объявить тип параметра пути в функции, используя стандартные аннотации типов Python.

```Python
from fastapi import FastAPI

app = FastAPI()


@app.get("/items/{item_id}")
async def read_item(item_id: int):
    return {"item_id": item_id}
```

Если запустите этот пример и перейдёте по адресу: [http://127.0.0.1:8000/items/3](http://127.0.0.1:8000/items/3), то увидите ответ:

```Python
{"item_id":3}
```

> Обратите внимание на значение `3`, которое получила (и вернула) функция. Это целочисленный Python `int`, а не строка `"3"`. Используя определения типов, **FastAPI** выполняет автоматический "парсинг" запросов.


















#### Jinja

**Jinja** — это механизм шаблонов, написанный на Python, предназначенный для облегчения процесса рендеринга ответов API. В каждом языке шаблонов есть переменные, которые заменяются фактическими значениями, переданными им при отображении шаблона, и есть теги, управляющие логикой шаблона.

Механизм шаблонов Jinja использует фигурные скобки `{ }`, чтобы отличить свои выражения и синтаксис от обычного HTML, текста и любой другой переменной в файле шаблона.

Синтаксис `{{ }}` называется блоком переменных. Синтаксис `{% %}` содержит управляющие структуры, такие как `if/else`, циклы и макросы.

Три общих синтаксических блока, используемых в языке шаблонов Jinja, включают следующее:
- `{% … %}` – Этот синтаксис используется для операторов, таких как управляющие структуры.
- `{{ todo.item }}` – Этот синтаксис используется для вывода значений переданных ему выражений.
- `{# This is a great API book! #}` – Этот синтаксис используется при написании комментариев и не отображается на веб-странице.

Несмотря на сходство синтаксиса `Python` и `Jinja`, такие модификации, как объединение строк, установка первого символа строки в верхний регистр и т. д., не могут быть выполнены с использованием синтаксиса Python в `Jinja`. Поэтому для выполнения таких модификаций у нас в `Jinja` есть **фильтры**.
Фильтр отделяется от переменной вертикальной чертой (`|`) и может содержать необязательные аргументы в круглых скобках. Фильтр определяется в формате:

```Python
{{ variable | filter_name(*args) }}
```

Если нет аргументов, определение становится следующим:

```Python
{{ variable | filter_name }}
```

**Фильтр по умолчанию**

Переменная фильтра по умолчанию используется для замены вывода переданного значения, если оно оказывается `None`:

```Python
{{ todo.item | default('This is a default todo item') }}
```

**Escape фильтр**

Этот фильтр используется для отображения необработанного вывода `HTML`:

```Python
{{ "<title>Todo Application</title>" | escape }}
```

**Фильтры преобразования**

Эти фильтры включают фильтры `int` и `float`, используемые для преобразования из одного типа данных в другой:

```Python
{{ 3.142 | int}}
{{ 31 | float }}
```

**Фильтр объединения**

Этот фильтр используется для объединения элементов списка в строку, как в Python:

```Python
{{ ['Packt', 'produces', 'great', 'books!'] | join(' ') }}
```

**Фильтр длины**

Этот фильтр используется для возврата длины переданного объекта. Он выполняет ту же роль, что и `len()` в Python:

```Python
Todo count: {{ todos | length }}
```

**Использование операторов if**

```Python
{% if todo | length < 5 %}
	You don't have much items on your todo list!
{% else %}
	You have a busy day it seems!
{% endif %}
```

**Циклы**

```Python
{% for todo in todos %}
	<b> {{ todo.item }} </b>
{% endfor %}
```

Вы можете получить доступ к специальным переменным внутри цикла `for`, таким как `loop.index`, который дает индекс текущей итерации и т.д..

**Макросы**

Макрос в `Jinja` — это функция, которая возвращает строку HTML. Основной вариант использования макросов — избежать повторения кода и вместо этого использовать один вызов функции. Например, макрос ввода определен для сокращения непрерывного определения тегов ввода в HTML-форме:

```Python
{% macro input(name, value='', type='text', size=20 %}
	<div class="form">
		<input type="{{ type }}" name="{{ name }}" value="{{ value|escape }}" size="{{ size }}">
	</div>
{% endmacro %}
```

Теперь, чтобы быстро создать ввод в вашей форме, вызывается макрос:

```Python
{{ input('item') }}
```

Это вернет следующее:

```HTML
<div class="form">
	<input type="text" name="item" value="" size="20">
</div>
```

**Наследование шаблонов**

Самая мощная функция `Jinja` — наследование шаблонов. Эта функция продвигает принцип «не повторяйся» (**DRY**) и удобна в больших веб-приложениях. Наследование шаблона — это ситуация, когда базовый шаблон определен, а дочерние шаблоны могут взаимодействовать, наследовать и заменять определенные разделы базового шаблона.










### 10.5.5 GraphQL

#TODO 

### 10.5.6 Gunicorn

**Gunicorn** написан на чистом Python. Он реализует стандарт **WSGI** (Web Server Gateway Interface), который предназначен для взаимодействия между приложением на Python, выполняющимся на сервере, и самим веб-сервером. Это нужно для того, чтобы отделить реализацию веб-сервера от кода приложения.

Процесс Gunicorn будет располагаться между веб-сервером и сервером приложения. Рисунок наглядно показывает цепочку: в качестве веб-сервера использован NGINX, затем расположился Gunicorn, в конце запущено приложение Django.

![[Pasted image 20230815170450.png]]

Установка Gunicorn в виртуальном окружении

```Shell
pip install gunicorn
```

После установки вам станет доступна команда gunicorn. Ей требуется один аргумент: модуль WSGI-совместимого приложения. django-admin предоставил его с самого начала. Это файл wsgi.py.

```
gunicorn <path_to_wsgi_file>.wsgi
```

